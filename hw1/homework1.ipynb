{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use textacy which is a lib on top of spacy to do some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: more_itertools in /misc/vlgscratch4/ChoGroup/kulikov/venv/parlai/lib/python3.6/site-packages (4.3.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.0.0 in /misc/vlgscratch4/ChoGroup/kulikov/venv/parlai/lib/python3.6/site-packages/six-1.11.0-py3.6.egg (from more_itertools) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "# run if you dont have it installed\n",
    "!pip install more_itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next cell is loading the training data disregarding NGRAM size and max vocabulary/max seq len size, it needs to be run only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6670b04edcaa4afb85d9c0b5a5de5373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f586231b3b4087acc51d8100593866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positive training samples : 12500 \n",
      "Negaitve training samples : 12500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a47fbaf11cc40b7bd6259a379628f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f1557e4b0742cc95e8bacb4a88e5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5cab438217473f94f663fc1c361f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5cd31b6a694eb89df35a9cd31a61c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word vocabulary size: 92929 words\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy\n",
    "import itertools\n",
    "from operator import itemgetter \n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "import re\n",
    "import more_itertools as mit  # not built-in package\n",
    "_tqdm = tqdm_notebook  # prolly you need jupyter widget for this, change for tqdm for simple tqdm\n",
    "\n",
    "# get the training data\n",
    "TRAIN_FILES_POS = glob('/home/kulikov/vlgwork/aclImdb/train/pos/*')\n",
    "pos_train_texts = []\n",
    "TRAIN_FILES_NEG = glob('/home/kulikov/vlgwork/aclImdb/train/neg/*')\n",
    "neg_train_texts = []\n",
    "\n",
    "# get training text in RAM\n",
    "for fname in _tqdm(TRAIN_FILES_NEG):\n",
    "    with open(fname, 'r') as f:\n",
    "        neg_train_texts.append(f.read())\n",
    "for fname in _tqdm(TRAIN_FILES_POS):\n",
    "    with open(fname, 'r') as f:\n",
    "        pos_train_texts.append(f.read())\n",
    "        \n",
    "print(\"Positive training samples : {} \\nNegaitve training samples : {}\".format(len(pos_train_texts), len(neg_train_texts)))\n",
    "\n",
    "TRAIN_SIZE=10000  # change this if you want\n",
    "                       \n",
    "# Split training data on train valid parts now\n",
    "pos_valid_texts = pos_train_texts[TRAIN_SIZE:]\n",
    "pos_train_texts = pos_train_texts[:TRAIN_SIZE]\n",
    "neg_valid_texts = neg_train_texts[TRAIN_SIZE:]\n",
    "neg_train_texts = neg_train_texts[:TRAIN_SIZE]\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "TAG_RE = re.compile(r'<[^>]+>') # get rid off HTML tags from the data\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def lower_case_remove_punc(parsed):\n",
    "    return [token.text.lower() for token in parsed if (token.text not in punctuations)] #and (token.is_stop is False)]\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    token_dataset = []\n",
    "    # we are keeping track of all tokens in dataset \n",
    "    # in order to create vocabulary later\n",
    "    all_tokens = []\n",
    "\n",
    "    for sample in _tqdm(tokenizer.pipe(dataset, disable=['parser', 'tagger', 'ner'], batch_size=512, n_threads=1)):\n",
    "        tokens = lower_case_remove_punc(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "        \n",
    "    return token_dataset, all_tokens\n",
    "                       \n",
    "#clean from html tags\n",
    "pos_valid_texts = [remove_tags(t) for t in pos_valid_texts]\n",
    "neg_valid_texts = [remove_tags(t) for t in neg_valid_texts]\n",
    "pos_train_texts = [remove_tags(t) for t in pos_train_texts]\n",
    "neg_train_texts = [remove_tags(t) for t in neg_train_texts]\n",
    "\n",
    "pos_valid_texts_toked, n1 =  tokenize_dataset(pos_valid_texts)\n",
    "neg_valid_texts_toked, n2 =  tokenize_dataset(neg_valid_texts)\n",
    "pos_train_texts_toked, n3 =  tokenize_dataset(pos_train_texts)\n",
    "neg_train_texts_toked, n4 =  tokenize_dataset(neg_train_texts)\n",
    "                       \n",
    "voc = list(set(n1 + n2 + n3 + n4))\n",
    "print('Word vocabulary size: {} words'.format(len(voc)))\n",
    "                       \n",
    "def find_ngrams(input_list, n):\n",
    "    result_list = []\n",
    "    for l in input_list:\n",
    "        result_list.append(list(zip(*[l[i:] for i in range(n)])))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW we split on ngrams, so change this accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAM = 2  # change this to make different N grams for each token\n",
    "# now make train and valid dicts\n",
    "\n",
    "train_data = {'pos': find_ngrams(pos_train_texts_toked, NGRAM),\n",
    "              'neg': find_ngrams(neg_train_texts_toked, NGRAM)}\n",
    "valid_data = {'pos': find_ngrams(pos_valid_texts_toked, NGRAM),\n",
    "             'neg': find_ngrams(neg_valid_texts_toked, NGRAM)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building vocabulary from all training data (including validation part), NOW we specify max voc size and put UNK for all rare tokens\n",
    "We also keep information about frquencies in order to be able to reduce voc size later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 43891 ; token ('some', 'suspense')\n",
      "Token ('some', 'suspense'); token id 43891\n"
     ]
    }
   ],
   "source": [
    "max_vocab_size = 100000\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "all_train_tokens = list(mit.flatten(train_data['pos'] + train_data['neg'] + valid_data['pos'] + valid_data['neg']))\n",
    "counted_tokens = Counter(all_train_tokens)\n",
    "\n",
    "vocab, count = zip(*counted_tokens.most_common(max_vocab_size))\n",
    "id2token = list(vocab)\n",
    "token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "id2token = ['<pad>', '<unk>'] + id2token\n",
    "token2id['<pad>'] = PAD_IDX \n",
    "token2id['<unk>'] = UNK_IDX\n",
    "\n",
    "# Lets check the dictionary by loading random token from it\n",
    "\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))\n",
    "\n",
    "def _text2id(doc):\n",
    "    return [token2id[t] if t in token2id else UNK_IDX for t in doc]\n",
    "\n",
    "def _id2text(vec):\n",
    "    return [id2token[i] for i in vec]\n",
    "    \n",
    "train_data_id = {}\n",
    "valid_data_id = {}\n",
    "\n",
    "train_data_id['pos'] = []\n",
    "for d in train_data['pos']:\n",
    "    train_data_id['pos'].append(_text2id(d))\n",
    "    \n",
    "train_data_id['neg'] = []\n",
    "for d in train_data['neg']:\n",
    "    train_data_id['neg'].append(_text2id(d))\n",
    "    \n",
    "valid_data_id['pos'] = []\n",
    "for d in valid_data['pos']:\n",
    "    valid_data_id['pos'].append(_text2id(d))\n",
    "    \n",
    "valid_data_id['neg'] = []\n",
    "for d in valid_data['neg']:\n",
    "    valid_data_id['neg'].append(_text2id(d))\n",
    "    \n",
    "train_data_id_merged = []\n",
    "valid_data_id_merged = []\n",
    "\n",
    "for d in train_data_id['pos']:\n",
    "    train_data_id_merged.append((d, 0))\n",
    "for d in train_data_id['neg']:\n",
    "    train_data_id_merged.append((d, 1))\n",
    "    \n",
    "for d in valid_data_id['pos']:\n",
    "    valid_data_id_merged.append((d, 0))\n",
    "for d in valid_data_id['neg']:\n",
    "    valid_data_id_merged.append((d, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making pytorch Dataset out of our set of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbDataset(Dataset):\n",
    "    def __init__(self, data_list, max_inp_length=None, device='cpu'):\n",
    "        \"\"\"\n",
    "        data_list is a list of tuples: (x,y) where x is a list of ids and y is a label\n",
    "        \"\"\"\n",
    "        self.data = data_list\n",
    "        self.max_len = max_inp_length\n",
    "        self.data_tensors = []\n",
    "        for (i, t) in tqdm_notebook(self.data):\n",
    "            \n",
    "            self.data_tensors.append((torch.LongTensor(i[:self.max_len]).to(device), torch.LongTensor([t]).to(device)))\n",
    "              \n",
    "    def __getitem__(self, key):\n",
    "        (inp, tgt) = self.data_tensors[key]\n",
    "        \n",
    "        return inp, tgt, len(inp)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def pad(tensor, length, dim=0, pad=0):\n",
    "    \"\"\"Pad tensor to a specific length.\n",
    "    :param tensor: vector to pad\n",
    "    :param length: new length\n",
    "    :param dim: (default 0) dimension to pad\n",
    "    :returns: padded tensor if the tensor is shorter than length\n",
    "    \"\"\"\n",
    "    if tensor.size(dim) < length:\n",
    "        return torch.cat(\n",
    "            [tensor, tensor.new(*tensor.size()[:dim],\n",
    "                                length - tensor.size(dim),\n",
    "                                *tensor.size()[dim + 1:]).fill_(pad)],\n",
    "            dim=dim)\n",
    "    else:\n",
    "        return tensor\n",
    "    \n",
    "def batchify(batch):\n",
    "    maxlen = max(batch, key = itemgetter(2))[-1]\n",
    "    batch_list = []\n",
    "    target_list = []\n",
    "    for b in batch:\n",
    "        batch_list.append(pad(b[0], maxlen, dim=0, pad=PAD_IDX))\n",
    "        target_list.append(b[1])\n",
    "    input_batch = torch.stack(batch_list, 0)\n",
    "    target_batch = torch.stack(target_list, 0)\n",
    "    \n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e0e4d211734b778dee495ad0202ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c55bc2f9fea4dd1830465ced8f0de77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ImdbDataset(train_data_id_merged, max_inp_length=None, device='cuda')\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, collate_fn=batchify, shuffle=True)\n",
    "\n",
    "valid_dataset = ImdbDataset(valid_data_id_merged, max_inp_length=None, device='cuda')\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=512, collate_fn=batchify, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating simple model for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BagOfNGrams(\n",
       "  (embedding): EmbeddingBag(100002, 30, mode=mean)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=30, out_features=2048, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.0)\n",
       "    (3): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BagOfNGrams(nn.Module):\n",
    "    def init_layers(self):\n",
    "        for l in self.layers:\n",
    "            if getattr(l, 'weight', None) is not None:\n",
    "                torch.nn.init.xavier_uniform_(l.weight)\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_dim=300, hidden_size=512, reduce='sum', nlayers=2, act='ReLU', nclasses=2, dropout=0.1, batch_norm=False):\n",
    "        super(BagOfNGrams, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.reduce = reduce\n",
    "        self.nlayers = nlayers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nclasses = nclasses\n",
    "        self.act = getattr(nn, act)\n",
    "        self.embedding = nn.EmbeddingBag(num_embeddings=vocab_size, embedding_dim=emb_dim, mode=reduce)\n",
    "        if batch_norm is True:\n",
    "            self.batch_norm = nn.BatchNorm1d(self.emb_dim)\n",
    "        #self.layers = nn.ModuleList([nn.Linear(self.emb_dim, 1)])\n",
    "        self.layers = nn.ModuleList([nn.Linear(self.emb_dim, self.hidden_size)])\n",
    "        self.layers.append(self.act())\n",
    "        self.layers.append(nn.Dropout(p=dropout))\n",
    "        for i in range(self.nlayers-2):\n",
    "            self.layers.append(nn.Linear(self.hidden_size, self.hidden_size))\n",
    "            self.layers.append(self.act())\n",
    "            self.layers.append(nn.Dropout(p=dropout))\n",
    "        self.layers.append(nn.Linear(self.hidden_size, 1))\n",
    "        self.init_layers()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        postemb = self.embedding(x)\n",
    "        if hasattr(self, 'batch_norm'):\n",
    "            x = self.batch_norm(postemb)\n",
    "        else:\n",
    "            x = postemb\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = BagOfNGrams(len(id2token), emb_dim=30, hidden_size=2048, act='Tanh', nlayers=1, reduce='mean', dropout=0.0, batch_norm=False)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60b1e8024dd465483002b4099210661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a5968d024c468a8447a92566f84dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa8d9a523374c6ab798b122b857975c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f15141233a404ab76d52f39651c3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f661d8424e41468b0015ded6d1405f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e996570f3549ed8a22afc7443833f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [6/20], Step: [40/40], Train loss: 0.3021753132343292, Validation Acc: 82.52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad33f02abc5446789672cb685d33887b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d84fcbd93864d56b3242b4e4dc461b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e20d13c0d64825b623bb2e631f9d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ee97de606f41959f4168b485d2454e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e967203a9e46e59302901575e955ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [11/20], Step: [40/40], Train loss: 0.0005129986093379557, Validation Acc: 87.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ec5e3ea02b4b54af3da48bef8ab334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66073f0705dc4584ae82736876e34e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d90708a12f4833ae6fc7e464983aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4c950465bb430ba0669dd5ec49a34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd9edd9dc1d490eba4956ab2d11147f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [16/20], Step: [40/40], Train loss: 7.480483327526599e-05, Validation Acc: 87.38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642bd41295b6490b85dabeb173865950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61456fd0ee8b44ddaf100e7642a78e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507f9a84b0534fdfb5c2b1cba9c79a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e5af7e5822440185e79494e8b7462b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "num_epochs = 20 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='elementwise_mean')\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.99, nesterov=True)\n",
    "#optimizer = torch.optim.Adagrad(params=model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=learning_rate)\n",
    "\n",
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, labels in loader:\n",
    "        outputs = torch.sigmoid(model(data))\n",
    "        predicted = (outputs > 0.5).long()\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in _tqdm(enumerate(train_loader)): \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        loss = criterion(outputs.view(-1), labels.float().view(-1))\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        #print('Train loss: {}'.format(loss.item()))\n",
    "        # validate every 100 iterations\n",
    "    if epoch % 5 == 0 and epoch > 0:\n",
    "        val_acc = test_model(loader=valid_loader, model=model)\n",
    "        print('Epoch: [{}/{}], Step: [{}/{}], Train loss: {}, Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), loss.item(), val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-dee10ddd5cb310f9a34f3b59baad8d2e"
       },
       "datasets": {
        "data-dee10ddd5cb310f9a34f3b59baad8d2e": [
         {
          "loss": 0.6951720714569092,
          "step": 0
         },
         {
          "loss": 27.67312240600586,
          "step": 1
         },
         {
          "loss": 52.542293548583984,
          "step": 2
         },
         {
          "loss": 61.942657470703125,
          "step": 3
         },
         {
          "loss": 22.995664596557617,
          "step": 4
         },
         {
          "loss": 29.90315055847168,
          "step": 5
         },
         {
          "loss": 40.0294189453125,
          "step": 6
         },
         {
          "loss": 35.65000915527344,
          "step": 7
         },
         {
          "loss": 8.785724639892578,
          "step": 8
         },
         {
          "loss": 34.091453552246094,
          "step": 9
         },
         {
          "loss": 47.04391098022461,
          "step": 10
         },
         {
          "loss": 43.96430206298828,
          "step": 11
         },
         {
          "loss": 27.21330451965332,
          "step": 12
         },
         {
          "loss": 2.219283103942871,
          "step": 13
         },
         {
          "loss": 35.2329216003418,
          "step": 14
         },
         {
          "loss": 57.7866325378418,
          "step": 15
         },
         {
          "loss": 60.64861297607422,
          "step": 16
         },
         {
          "loss": 50.56422805786133,
          "step": 17
         },
         {
          "loss": 24.779644012451172,
          "step": 18
         },
         {
          "loss": 6.8449296951293945,
          "step": 19
         },
         {
          "loss": 21.478538513183594,
          "step": 20
         },
         {
          "loss": 25.46550178527832,
          "step": 21
         },
         {
          "loss": 17.13551139831543,
          "step": 22
         },
         {
          "loss": 2.725285530090332,
          "step": 23
         },
         {
          "loss": 8.51980972290039,
          "step": 24
         },
         {
          "loss": 3.8456778526306152,
          "step": 25
         },
         {
          "loss": 12.526845932006836,
          "step": 26
         },
         {
          "loss": 14.191388130187988,
          "step": 27
         },
         {
          "loss": 6.320071697235107,
          "step": 28
         },
         {
          "loss": 12.816993713378906,
          "step": 29
         },
         {
          "loss": 16.51491355895996,
          "step": 30
         },
         {
          "loss": 10.854734420776367,
          "step": 31
         },
         {
          "loss": 4.157623291015625,
          "step": 32
         },
         {
          "loss": 7.002695083618164,
          "step": 33
         },
         {
          "loss": 1.6613736152648926,
          "step": 34
         },
         {
          "loss": 1.0040696859359741,
          "step": 35
         },
         {
          "loss": 5.0106120109558105,
          "step": 36
         },
         {
          "loss": 1.2940601110458374,
          "step": 37
         },
         {
          "loss": 2.3727314472198486,
          "step": 38
         },
         {
          "loss": 4.329563617706299,
          "step": 39
         },
         {
          "loss": 5.35907506942749,
          "step": 40
         },
         {
          "loss": 4.512312412261963,
          "step": 41
         },
         {
          "loss": 4.157193660736084,
          "step": 42
         },
         {
          "loss": 7.510709285736084,
          "step": 43
         },
         {
          "loss": 8.391938209533691,
          "step": 44
         },
         {
          "loss": 1.1430989503860474,
          "step": 45
         },
         {
          "loss": 2.052678346633911,
          "step": 46
         },
         {
          "loss": 7.7784576416015625,
          "step": 47
         },
         {
          "loss": 3.8325388431549072,
          "step": 48
         },
         {
          "loss": 8.48808479309082,
          "step": 49
         },
         {
          "loss": 8.38128662109375,
          "step": 50
         },
         {
          "loss": 1.9029024839401245,
          "step": 51
         },
         {
          "loss": 0.7924166917800903,
          "step": 52
         },
         {
          "loss": 3.817716598510742,
          "step": 53
         },
         {
          "loss": 1.9705535173416138,
          "step": 54
         },
         {
          "loss": 1.7976473569869995,
          "step": 55
         },
         {
          "loss": 3.8069558143615723,
          "step": 56
         },
         {
          "loss": 0.8572786450386047,
          "step": 57
         },
         {
          "loss": 6.942056655883789,
          "step": 58
         },
         {
          "loss": 3.288761615753174,
          "step": 59
         },
         {
          "loss": 9.566328048706055,
          "step": 60
         },
         {
          "loss": 14.002321243286133,
          "step": 61
         },
         {
          "loss": 4.754101276397705,
          "step": 62
         },
         {
          "loss": 12.449238777160645,
          "step": 63
         },
         {
          "loss": 14.914989471435547,
          "step": 64
         },
         {
          "loss": 7.5256266593933105,
          "step": 65
         },
         {
          "loss": 8.87238883972168,
          "step": 66
         },
         {
          "loss": 10.916378021240234,
          "step": 67
         },
         {
          "loss": 6.297557353973389,
          "step": 68
         },
         {
          "loss": 8.997160911560059,
          "step": 69
         },
         {
          "loss": 12.65839672088623,
          "step": 70
         },
         {
          "loss": 5.686122417449951,
          "step": 71
         },
         {
          "loss": 11.552227973937988,
          "step": 72
         },
         {
          "loss": 15.30650806427002,
          "step": 73
         },
         {
          "loss": 7.575497150421143,
          "step": 74
         },
         {
          "loss": 10.473326683044434,
          "step": 75
         },
         {
          "loss": 14.319091796875,
          "step": 76
         },
         {
          "loss": 7.42215633392334,
          "step": 77
         },
         {
          "loss": 11.38484001159668,
          "step": 78
         },
         {
          "loss": 13.402661323547363,
          "step": 79
         },
         {
          "loss": 7.662227630615234,
          "step": 80
         },
         {
          "loss": 11.307968139648438,
          "step": 81
         },
         {
          "loss": 9.707113265991211,
          "step": 82
         },
         {
          "loss": 1.5284279584884644,
          "step": 83
         },
         {
          "loss": 3.7962183952331543,
          "step": 84
         },
         {
          "loss": 1.8661797046661377,
          "step": 85
         },
         {
          "loss": 4.138279438018799,
          "step": 86
         },
         {
          "loss": 4.298017501831055,
          "step": 87
         },
         {
          "loss": 2.0065460205078125,
          "step": 88
         },
         {
          "loss": 9.074666023254395,
          "step": 89
         },
         {
          "loss": 6.531696319580078,
          "step": 90
         },
         {
          "loss": 6.188533306121826,
          "step": 91
         },
         {
          "loss": 8.070069313049316,
          "step": 92
         },
         {
          "loss": 1.5179551839828491,
          "step": 93
         },
         {
          "loss": 1.3146625757217407,
          "step": 94
         },
         {
          "loss": 7.105038166046143,
          "step": 95
         },
         {
          "loss": 3.577928304672241,
          "step": 96
         },
         {
          "loss": 11.336214065551758,
          "step": 97
         },
         {
          "loss": 12.44797134399414,
          "step": 98
         },
         {
          "loss": 3.971994400024414,
          "step": 99
         },
         {
          "loss": 15.68354320526123,
          "step": 100
         },
         {
          "loss": 21.27634620666504,
          "step": 101
         },
         {
          "loss": 13.621315956115723,
          "step": 102
         },
         {
          "loss": 4.094053745269775,
          "step": 103
         },
         {
          "loss": 8.648353576660156,
          "step": 104
         },
         {
          "loss": 1.4343805313110352,
          "step": 105
         },
         {
          "loss": 14.373468399047852,
          "step": 106
         },
         {
          "loss": 16.89128875732422,
          "step": 107
         },
         {
          "loss": 8.621430397033691,
          "step": 108
         },
         {
          "loss": 9.740900039672852,
          "step": 109
         },
         {
          "loss": 16.714933395385742,
          "step": 110
         },
         {
          "loss": 9.340960502624512,
          "step": 111
         },
         {
          "loss": 6.289310932159424,
          "step": 112
         },
         {
          "loss": 11.501270294189453,
          "step": 113
         },
         {
          "loss": 4.369138240814209,
          "step": 114
         },
         {
          "loss": 12.353041648864746,
          "step": 115
         },
         {
          "loss": 17.727619171142578,
          "step": 116
         },
         {
          "loss": 8.727730751037598,
          "step": 117
         },
         {
          "loss": 8.778127670288086,
          "step": 118
         },
         {
          "loss": 16.822189331054688,
          "step": 119
         },
         {
          "loss": 4.200458526611328,
          "step": 120
         },
         {
          "loss": 14.439265251159668,
          "step": 121
         },
         {
          "loss": 21.33404541015625,
          "step": 122
         },
         {
          "loss": 14.036433219909668,
          "step": 123
         },
         {
          "loss": 1.7879294157028198,
          "step": 124
         },
         {
          "loss": 6.53568172454834,
          "step": 125
         },
         {
          "loss": 0.8706574440002441,
          "step": 126
         },
         {
          "loss": 1.5056217908859253,
          "step": 127
         },
         {
          "loss": 6.406529426574707,
          "step": 128
         },
         {
          "loss": 3.417289972305298,
          "step": 129
         },
         {
          "loss": 10.70008373260498,
          "step": 130
         },
         {
          "loss": 11.889525413513184,
          "step": 131
         },
         {
          "loss": 2.124469518661499,
          "step": 132
         },
         {
          "loss": 18.0744571685791,
          "step": 133
         },
         {
          "loss": 25.17833137512207,
          "step": 134
         },
         {
          "loss": 19.665943145751953,
          "step": 135
         },
         {
          "loss": 3.4555065631866455,
          "step": 136
         },
         {
          "loss": 20.34554100036621,
          "step": 137
         },
         {
          "loss": 32.53782272338867,
          "step": 138
         },
         {
          "loss": 31.796281814575195,
          "step": 139
         },
         {
          "loss": 21.629310607910156,
          "step": 140
         },
         {
          "loss": 3.0739593505859375,
          "step": 141
         },
         {
          "loss": 26.52654457092285,
          "step": 142
         },
         {
          "loss": 39.79750061035156,
          "step": 143
         },
         {
          "loss": 43.22640609741211,
          "step": 144
         },
         {
          "loss": 36.993186950683594,
          "step": 145
         },
         {
          "loss": 15.907231330871582,
          "step": 146
         },
         {
          "loss": 10.938216209411621,
          "step": 147
         },
         {
          "loss": 25.233036041259766,
          "step": 148
         },
         {
          "loss": 27.668781280517578,
          "step": 149
         },
         {
          "loss": 18.86714744567871,
          "step": 150
         },
         {
          "loss": 2.0600247383117676,
          "step": 151
         },
         {
          "loss": 10.175134658813477,
          "step": 152
         },
         {
          "loss": 6.902927398681641,
          "step": 153
         },
         {
          "loss": 4.967008590698242,
          "step": 154
         },
         {
          "loss": 6.0063958168029785,
          "step": 155
         },
         {
          "loss": 3.0722975730895996,
          "step": 156
         },
         {
          "loss": 2.344754934310913,
          "step": 157
         },
         {
          "loss": 7.587873458862305,
          "step": 158
         },
         {
          "loss": 5.6148362159729,
          "step": 159
         },
         {
          "loss": 1.093616008758545,
          "step": 160
         },
         {
          "loss": 1.5824658870697021,
          "step": 161
         },
         {
          "loss": 7.062843322753906,
          "step": 162
         },
         {
          "loss": 4.930833339691162,
          "step": 163
         },
         {
          "loss": 5.940114498138428,
          "step": 164
         },
         {
          "loss": 7.753982067108154,
          "step": 165
         },
         {
          "loss": 0.8672216534614563,
          "step": 166
         },
         {
          "loss": 5.790849685668945,
          "step": 167
         },
         {
          "loss": 3.453101873397827,
          "step": 168
         },
         {
          "loss": 9.943058013916016,
          "step": 169
         },
         {
          "loss": 10.668566703796387,
          "step": 170
         },
         {
          "loss": 2.5275142192840576,
          "step": 171
         },
         {
          "loss": 16.23973274230957,
          "step": 172
         },
         {
          "loss": 16.98242950439453,
          "step": 173
         },
         {
          "loss": 16.041410446166992,
          "step": 174
         },
         {
          "loss": 2.5586211681365967,
          "step": 175
         },
         {
          "loss": 18.27701759338379,
          "step": 176
         },
         {
          "loss": 24.92688751220703,
          "step": 177
         },
         {
          "loss": 22.14847183227539,
          "step": 178
         },
         {
          "loss": 11.065563201904297,
          "step": 179
         },
         {
          "loss": 6.486137390136719,
          "step": 180
         },
         {
          "loss": 11.787599563598633,
          "step": 181
         },
         {
          "loss": 8.797056198120117,
          "step": 182
         },
         {
          "loss": 4.130472183227539,
          "step": 183
         },
         {
          "loss": 5.743927478790283,
          "step": 184
         },
         {
          "loss": 1.3718774318695068,
          "step": 185
         },
         {
          "loss": 4.866337776184082,
          "step": 186
         },
         {
          "loss": 0.8397427201271057,
          "step": 187
         },
         {
          "loss": 3.986543655395508,
          "step": 188
         },
         {
          "loss": 2.1316635608673096,
          "step": 189
         },
         {
          "loss": 4.196159362792969,
          "step": 190
         },
         {
          "loss": 6.263831615447998,
          "step": 191
         },
         {
          "loss": 1.0859906673431396,
          "step": 192
         },
         {
          "loss": 2.5846002101898193,
          "step": 193
         },
         {
          "loss": 2.33248233795166,
          "step": 194
         },
         {
          "loss": 0.9974261522293091,
          "step": 195
         },
         {
          "loss": 4.69334077835083,
          "step": 196
         },
         {
          "loss": 1.5516115427017212,
          "step": 197
         },
         {
          "loss": 0.5910614132881165,
          "step": 198
         },
         {
          "loss": 1.3328598737716675,
          "step": 199
         },
         {
          "loss": 4.283977508544922,
          "step": 200
         },
         {
          "loss": 2.1152679920196533,
          "step": 201
         },
         {
          "loss": 3.4324285984039307,
          "step": 202
         },
         {
          "loss": 1.8113840818405151,
          "step": 203
         },
         {
          "loss": 4.3237433433532715,
          "step": 204
         },
         {
          "loss": 0.7280203104019165,
          "step": 205
         },
         {
          "loss": 1.8050075769424438,
          "step": 206
         },
         {
          "loss": 3.911808967590332,
          "step": 207
         },
         {
          "loss": 1.9961779117584229,
          "step": 208
         },
         {
          "loss": 7.9508137702941895,
          "step": 209
         },
         {
          "loss": 2.9966187477111816,
          "step": 210
         },
         {
          "loss": 9.32853889465332,
          "step": 211
         },
         {
          "loss": 6.149867057800293,
          "step": 212
         },
         {
          "loss": 4.554441452026367,
          "step": 213
         },
         {
          "loss": 6.446130752563477,
          "step": 214
         },
         {
          "loss": 0.5819341540336609,
          "step": 215
         },
         {
          "loss": 6.138797760009766,
          "step": 216
         },
         {
          "loss": 2.9835824966430664,
          "step": 217
         },
         {
          "loss": 7.789567470550537,
          "step": 218
         },
         {
          "loss": 6.005598545074463,
          "step": 219
         },
         {
          "loss": 0.463284969329834,
          "step": 220
         },
         {
          "loss": 4.3276166915893555,
          "step": 221
         },
         {
          "loss": 4.2574663162231445,
          "step": 222
         },
         {
          "loss": 3.365891933441162,
          "step": 223
         },
         {
          "loss": 3.1184918880462646,
          "step": 224
         },
         {
          "loss": 0.8158950209617615,
          "step": 225
         },
         {
          "loss": 5.173663139343262,
          "step": 226
         },
         {
          "loss": 1.536083459854126,
          "step": 227
         },
         {
          "loss": 1.4770491123199463,
          "step": 228
         },
         {
          "loss": 3.004551410675049,
          "step": 229
         },
         {
          "loss": 1.0921244621276855,
          "step": 230
         },
         {
          "loss": 1.7369352579116821,
          "step": 231
         },
         {
          "loss": 1.930888295173645,
          "step": 232
         },
         {
          "loss": 0.9844416379928589,
          "step": 233
         },
         {
          "loss": 2.0247645378112793,
          "step": 234
         },
         {
          "loss": 2.646784543991089,
          "step": 235
         },
         {
          "loss": 0.748419463634491,
          "step": 236
         },
         {
          "loss": 2.0055224895477295,
          "step": 237
         },
         {
          "loss": 2.036848545074463,
          "step": 238
         },
         {
          "loss": 0.3021753132343292,
          "step": 239
         },
         {
          "loss": 0.5300589799880981,
          "step": 240
         },
         {
          "loss": 0.8884064555168152,
          "step": 241
         },
         {
          "loss": 0.5879485607147217,
          "step": 242
         },
         {
          "loss": 0.49970543384552,
          "step": 243
         },
         {
          "loss": 0.924006462097168,
          "step": 244
         },
         {
          "loss": 0.6636238694190979,
          "step": 245
         },
         {
          "loss": 0.3566094636917114,
          "step": 246
         },
         {
          "loss": 0.554630696773529,
          "step": 247
         },
         {
          "loss": 0.8949683308601379,
          "step": 248
         },
         {
          "loss": 0.3863636553287506,
          "step": 249
         },
         {
          "loss": 0.357827752828598,
          "step": 250
         },
         {
          "loss": 0.49707669019699097,
          "step": 251
         },
         {
          "loss": 0.38331159949302673,
          "step": 252
         },
         {
          "loss": 0.4193136394023895,
          "step": 253
         },
         {
          "loss": 0.26479610800743103,
          "step": 254
         },
         {
          "loss": 0.3865315616130829,
          "step": 255
         },
         {
          "loss": 0.26571351289749146,
          "step": 256
         },
         {
          "loss": 0.3719002604484558,
          "step": 257
         },
         {
          "loss": 0.2665160298347473,
          "step": 258
         },
         {
          "loss": 0.1629234403371811,
          "step": 259
         },
         {
          "loss": 0.22685606777668,
          "step": 260
         },
         {
          "loss": 0.17822305858135223,
          "step": 261
         },
         {
          "loss": 0.15206626057624817,
          "step": 262
         },
         {
          "loss": 0.28693804144859314,
          "step": 263
         },
         {
          "loss": 0.11812610924243927,
          "step": 264
         },
         {
          "loss": 0.19199897348880768,
          "step": 265
         },
         {
          "loss": 0.11762893199920654,
          "step": 266
         },
         {
          "loss": 0.18708398938179016,
          "step": 267
         },
         {
          "loss": 0.18456029891967773,
          "step": 268
         },
         {
          "loss": 0.17564107477664948,
          "step": 269
         },
         {
          "loss": 0.13339553773403168,
          "step": 270
         },
         {
          "loss": 0.15809237957000732,
          "step": 271
         },
         {
          "loss": 0.18715520203113556,
          "step": 272
         },
         {
          "loss": 0.2137489914894104,
          "step": 273
         },
         {
          "loss": 0.2310480773448944,
          "step": 274
         },
         {
          "loss": 0.22383709251880646,
          "step": 275
         },
         {
          "loss": 0.1747199296951294,
          "step": 276
         },
         {
          "loss": 0.25983455777168274,
          "step": 277
         },
         {
          "loss": 0.2192298024892807,
          "step": 278
         },
         {
          "loss": 0.010929507203400135,
          "step": 279
         },
         {
          "loss": 0.3294644057750702,
          "step": 280
         },
         {
          "loss": 0.14069770276546478,
          "step": 281
         },
         {
          "loss": 0.325540691614151,
          "step": 282
         },
         {
          "loss": 0.07497677206993103,
          "step": 283
         },
         {
          "loss": 0.19212406873703003,
          "step": 284
         },
         {
          "loss": 0.16462023556232452,
          "step": 285
         },
         {
          "loss": 0.11909931153059006,
          "step": 286
         },
         {
          "loss": 0.20311155915260315,
          "step": 287
         },
         {
          "loss": 0.1315169781446457,
          "step": 288
         },
         {
          "loss": 0.10510403662919998,
          "step": 289
         },
         {
          "loss": 0.17363321781158447,
          "step": 290
         },
         {
          "loss": 0.10852625221014023,
          "step": 291
         },
         {
          "loss": 0.06925873458385468,
          "step": 292
         },
         {
          "loss": 0.14535430073738098,
          "step": 293
         },
         {
          "loss": 0.1238502636551857,
          "step": 294
         },
         {
          "loss": 0.1168116107583046,
          "step": 295
         },
         {
          "loss": 0.05593881011009216,
          "step": 296
         },
         {
          "loss": 0.08304643630981445,
          "step": 297
         },
         {
          "loss": 0.13986675441265106,
          "step": 298
         },
         {
          "loss": 0.037482667714357376,
          "step": 299
         },
         {
          "loss": 0.048111096024513245,
          "step": 300
         },
         {
          "loss": 0.12830710411071777,
          "step": 301
         },
         {
          "loss": 0.10010621696710587,
          "step": 302
         },
         {
          "loss": 0.08223649114370346,
          "step": 303
         },
         {
          "loss": 0.09825000911951065,
          "step": 304
         },
         {
          "loss": 0.0847812369465828,
          "step": 305
         },
         {
          "loss": 0.09560538828372955,
          "step": 306
         },
         {
          "loss": 0.08394160121679306,
          "step": 307
         },
         {
          "loss": 0.08944924920797348,
          "step": 308
         },
         {
          "loss": 0.0615554116666317,
          "step": 309
         },
         {
          "loss": 0.1152644082903862,
          "step": 310
         },
         {
          "loss": 0.07305827736854553,
          "step": 311
         },
         {
          "loss": 0.06033182144165039,
          "step": 312
         },
         {
          "loss": 0.0570702962577343,
          "step": 313
         },
         {
          "loss": 0.06994190812110901,
          "step": 314
         },
         {
          "loss": 0.06973172724246979,
          "step": 315
         },
         {
          "loss": 0.18724793195724487,
          "step": 316
         },
         {
          "loss": 0.08745885640382767,
          "step": 317
         },
         {
          "loss": 0.24442842602729797,
          "step": 318
         },
         {
          "loss": 0.021521830931305885,
          "step": 319
         },
         {
          "loss": 0.09638508409261703,
          "step": 320
         },
         {
          "loss": 0.06439260393381119,
          "step": 321
         },
         {
          "loss": 0.06305953860282898,
          "step": 322
         },
         {
          "loss": 0.04909108206629753,
          "step": 323
         },
         {
          "loss": 0.021571120247244835,
          "step": 324
         },
         {
          "loss": 0.048279307782649994,
          "step": 325
         },
         {
          "loss": 0.06615431606769562,
          "step": 326
         },
         {
          "loss": 0.05839402973651886,
          "step": 327
         },
         {
          "loss": 0.04116933420300484,
          "step": 328
         },
         {
          "loss": 0.03334779664874077,
          "step": 329
         },
         {
          "loss": 0.050410863012075424,
          "step": 330
         },
         {
          "loss": 0.045762427151203156,
          "step": 331
         },
         {
          "loss": 0.06456848233938217,
          "step": 332
         },
         {
          "loss": 0.0368734672665596,
          "step": 333
         },
         {
          "loss": 0.04834591597318649,
          "step": 334
         },
         {
          "loss": 0.044114354997873306,
          "step": 335
         },
         {
          "loss": 0.020747000351548195,
          "step": 336
         },
         {
          "loss": 0.02226055972278118,
          "step": 337
         },
         {
          "loss": 0.03200284764170647,
          "step": 338
         },
         {
          "loss": 0.04210120067000389,
          "step": 339
         },
         {
          "loss": 0.027175724506378174,
          "step": 340
         },
         {
          "loss": 0.024358859285712242,
          "step": 341
         },
         {
          "loss": 0.06019098311662674,
          "step": 342
         },
         {
          "loss": 0.03236782178282738,
          "step": 343
         },
         {
          "loss": 0.023262279108166695,
          "step": 344
         },
         {
          "loss": 0.03796962648630142,
          "step": 345
         },
         {
          "loss": 0.020870093256235123,
          "step": 346
         },
         {
          "loss": 0.03532210737466812,
          "step": 347
         },
         {
          "loss": 0.04971521347761154,
          "step": 348
         },
         {
          "loss": 0.019452879205346107,
          "step": 349
         },
         {
          "loss": 0.048581939190626144,
          "step": 350
         },
         {
          "loss": 0.011223101988434792,
          "step": 351
         },
         {
          "loss": 0.040963031351566315,
          "step": 352
         },
         {
          "loss": 0.0367119163274765,
          "step": 353
         },
         {
          "loss": 0.03565488010644913,
          "step": 354
         },
         {
          "loss": 0.04901312664151192,
          "step": 355
         },
         {
          "loss": 0.05805978551506996,
          "step": 356
         },
         {
          "loss": 0.05257011950016022,
          "step": 357
         },
         {
          "loss": 0.015309124253690243,
          "step": 358
         },
         {
          "loss": 0.0019710722845047712,
          "step": 359
         },
         {
          "loss": 0.04128571227192879,
          "step": 360
         },
         {
          "loss": 0.036289576441049576,
          "step": 361
         },
         {
          "loss": 0.027671923860907555,
          "step": 362
         },
         {
          "loss": 0.012187802232801914,
          "step": 363
         },
         {
          "loss": 0.0038118755910545588,
          "step": 364
         },
         {
          "loss": 0.008334800601005554,
          "step": 365
         },
         {
          "loss": 0.013889282941818237,
          "step": 366
         },
         {
          "loss": 0.009294753894209862,
          "step": 367
         },
         {
          "loss": 0.009910348802804947,
          "step": 368
         },
         {
          "loss": 0.023851659148931503,
          "step": 369
         },
         {
          "loss": 0.009531669318675995,
          "step": 370
         },
         {
          "loss": 0.0041007692925632,
          "step": 371
         },
         {
          "loss": 0.021230017766356468,
          "step": 372
         },
         {
          "loss": 0.0058123948983848095,
          "step": 373
         },
         {
          "loss": 0.0014309455873444676,
          "step": 374
         },
         {
          "loss": 0.009241217747330666,
          "step": 375
         },
         {
          "loss": 0.022889062762260437,
          "step": 376
         },
         {
          "loss": 0.007061416283249855,
          "step": 377
         },
         {
          "loss": 0.005500763189047575,
          "step": 378
         },
         {
          "loss": 0.02389574982225895,
          "step": 379
         },
         {
          "loss": 0.017990361899137497,
          "step": 380
         },
         {
          "loss": 0.005169200245290995,
          "step": 381
         },
         {
          "loss": 0.01059039868414402,
          "step": 382
         },
         {
          "loss": 0.0038082075770944357,
          "step": 383
         },
         {
          "loss": 0.014155762270092964,
          "step": 384
         },
         {
          "loss": 0.012023909948766232,
          "step": 385
         },
         {
          "loss": 0.004320712760090828,
          "step": 386
         },
         {
          "loss": 0.03772379085421562,
          "step": 387
         },
         {
          "loss": 0.006117886397987604,
          "step": 388
         },
         {
          "loss": 0.011461315676569939,
          "step": 389
         },
         {
          "loss": 0.020845891907811165,
          "step": 390
         },
         {
          "loss": 0.0026144208386540413,
          "step": 391
         },
         {
          "loss": 0.009702228009700775,
          "step": 392
         },
         {
          "loss": 0.003861477365717292,
          "step": 393
         },
         {
          "loss": 0.008372503332793713,
          "step": 394
         },
         {
          "loss": 0.028876908123493195,
          "step": 395
         },
         {
          "loss": 0.03959939628839493,
          "step": 396
         },
         {
          "loss": 0.009077023714780807,
          "step": 397
         },
         {
          "loss": 0.013128457590937614,
          "step": 398
         },
         {
          "loss": 0.00048045002040453255,
          "step": 399
         },
         {
          "loss": 0.0017298802267760038,
          "step": 400
         },
         {
          "loss": 0.001980646513402462,
          "step": 401
         },
         {
          "loss": 0.008623044937849045,
          "step": 402
         },
         {
          "loss": 0.0011749776313081384,
          "step": 403
         },
         {
          "loss": 0.0012059445725753903,
          "step": 404
         },
         {
          "loss": 0.003763542277738452,
          "step": 405
         },
         {
          "loss": 0.004184001591056585,
          "step": 406
         },
         {
          "loss": 0.02172664925456047,
          "step": 407
         },
         {
          "loss": 0.0012051230296492577,
          "step": 408
         },
         {
          "loss": 0.0009411525097675622,
          "step": 409
         },
         {
          "loss": 0.008629104122519493,
          "step": 410
         },
         {
          "loss": 0.0012878372799605131,
          "step": 411
         },
         {
          "loss": 0.004236246924847364,
          "step": 412
         },
         {
          "loss": 0.004794393666088581,
          "step": 413
         },
         {
          "loss": 0.0155335059389472,
          "step": 414
         },
         {
          "loss": 0.018850654363632202,
          "step": 415
         },
         {
          "loss": 0.015635764226317406,
          "step": 416
         },
         {
          "loss": 0.00688767759129405,
          "step": 417
         },
         {
          "loss": 0.00687784468755126,
          "step": 418
         },
         {
          "loss": 0.0008604482281953096,
          "step": 419
         },
         {
          "loss": 0.0024462298024445772,
          "step": 420
         },
         {
          "loss": 0.0033003573771566153,
          "step": 421
         },
         {
          "loss": 0.0068561420775949955,
          "step": 422
         },
         {
          "loss": 0.009538229554891586,
          "step": 423
         },
         {
          "loss": 0.0019378903089091182,
          "step": 424
         },
         {
          "loss": 0.0011701752664521337,
          "step": 425
         },
         {
          "loss": 0.017292147502303123,
          "step": 426
         },
         {
          "loss": 0.008435098454356194,
          "step": 427
         },
         {
          "loss": 0.0024752651806920767,
          "step": 428
         },
         {
          "loss": 0.0005814313190057874,
          "step": 429
         },
         {
          "loss": 0.001642738119699061,
          "step": 430
         },
         {
          "loss": 0.008978365920484066,
          "step": 431
         },
         {
          "loss": 0.003414464183151722,
          "step": 432
         },
         {
          "loss": 0.002104200189933181,
          "step": 433
         },
         {
          "loss": 0.001904491800814867,
          "step": 434
         },
         {
          "loss": 0.0032413764856755733,
          "step": 435
         },
         {
          "loss": 0.002903128042817116,
          "step": 436
         },
         {
          "loss": 0.0012289296137169003,
          "step": 437
         },
         {
          "loss": 0.0022498148027807474,
          "step": 438
         },
         {
          "loss": 0.0005129986093379557,
          "step": 439
         },
         {
          "loss": 0.00610552541911602,
          "step": 440
         },
         {
          "loss": 0.003653653897345066,
          "step": 441
         },
         {
          "loss": 0.0007720699068158865,
          "step": 442
         },
         {
          "loss": 0.0011541408021003008,
          "step": 443
         },
         {
          "loss": 0.003728547366335988,
          "step": 444
         },
         {
          "loss": 0.0017987570026889443,
          "step": 445
         },
         {
          "loss": 0.0009710707236081362,
          "step": 446
         },
         {
          "loss": 0.0016987938433885574,
          "step": 447
         },
         {
          "loss": 0.0010734043316915631,
          "step": 448
         },
         {
          "loss": 0.0009799196850508451,
          "step": 449
         },
         {
          "loss": 0.0006241586524993181,
          "step": 450
         },
         {
          "loss": 0.0009113185224123299,
          "step": 451
         },
         {
          "loss": 0.0005409807781688869,
          "step": 452
         },
         {
          "loss": 0.0033298556227236986,
          "step": 453
         },
         {
          "loss": 0.002568270079791546,
          "step": 454
         },
         {
          "loss": 0.0011403672397136688,
          "step": 455
         },
         {
          "loss": 0.000996066490188241,
          "step": 456
         },
         {
          "loss": 0.0007511351723223925,
          "step": 457
         },
         {
          "loss": 0.0006231196457520127,
          "step": 458
         },
         {
          "loss": 0.0012244220124557614,
          "step": 459
         },
         {
          "loss": 0.01348394900560379,
          "step": 460
         },
         {
          "loss": 0.002904890337958932,
          "step": 461
         },
         {
          "loss": 0.000573371653445065,
          "step": 462
         },
         {
          "loss": 0.001995509723201394,
          "step": 463
         },
         {
          "loss": 0.0021940567530691624,
          "step": 464
         },
         {
          "loss": 0.010985184460878372,
          "step": 465
         },
         {
          "loss": 0.001994180493056774,
          "step": 466
         },
         {
          "loss": 0.0024683407973498106,
          "step": 467
         },
         {
          "loss": 0.000689274980686605,
          "step": 468
         },
         {
          "loss": 0.0015954339178279042,
          "step": 469
         },
         {
          "loss": 0.01378711685538292,
          "step": 470
         },
         {
          "loss": 0.003746960312128067,
          "step": 471
         },
         {
          "loss": 0.0003670052974484861,
          "step": 472
         },
         {
          "loss": 0.0010439179604873061,
          "step": 473
         },
         {
          "loss": 0.0007309494540095329,
          "step": 474
         },
         {
          "loss": 0.0027123866602778435,
          "step": 475
         },
         {
          "loss": 0.0008696509758010507,
          "step": 476
         },
         {
          "loss": 0.00836137868463993,
          "step": 477
         },
         {
          "loss": 0.0008451384492218494,
          "step": 478
         },
         {
          "loss": 0.00024361666874028742,
          "step": 479
         },
         {
          "loss": 0.008627076633274555,
          "step": 480
         },
         {
          "loss": 0.0004134048940613866,
          "step": 481
         },
         {
          "loss": 0.0006029013311490417,
          "step": 482
         },
         {
          "loss": 0.0009541715844534338,
          "step": 483
         },
         {
          "loss": 0.004360768012702465,
          "step": 484
         },
         {
          "loss": 0.00246472773142159,
          "step": 485
         },
         {
          "loss": 0.0011834176257252693,
          "step": 486
         },
         {
          "loss": 0.004134064074605703,
          "step": 487
         },
         {
          "loss": 0.0005315548623912036,
          "step": 488
         },
         {
          "loss": 0.0038269886281341314,
          "step": 489
         },
         {
          "loss": 0.00042390701128169894,
          "step": 490
         },
         {
          "loss": 0.00039381670649163425,
          "step": 491
         },
         {
          "loss": 0.0005893592024222016,
          "step": 492
         },
         {
          "loss": 0.001954471692442894,
          "step": 493
         },
         {
          "loss": 0.0018540708115324378,
          "step": 494
         },
         {
          "loss": 0.003441684413701296,
          "step": 495
         },
         {
          "loss": 0.0004115724004805088,
          "step": 496
         },
         {
          "loss": 0.0007780903251841664,
          "step": 497
         },
         {
          "loss": 0.0005411409656517208,
          "step": 498
         },
         {
          "loss": 0.00029102282132953405,
          "step": 499
         },
         {
          "loss": 0.0007554339244961739,
          "step": 500
         },
         {
          "loss": 0.0011135879904031754,
          "step": 501
         },
         {
          "loss": 0.004200073424726725,
          "step": 502
         },
         {
          "loss": 0.00038220855640247464,
          "step": 503
         },
         {
          "loss": 0.0006823788280598819,
          "step": 504
         },
         {
          "loss": 0.00027696904726326466,
          "step": 505
         },
         {
          "loss": 0.01106483768671751,
          "step": 506
         },
         {
          "loss": 0.00039705735980533063,
          "step": 507
         },
         {
          "loss": 0.0006905450718477368,
          "step": 508
         },
         {
          "loss": 0.004947899375110865,
          "step": 509
         },
         {
          "loss": 0.0003018348943442106,
          "step": 510
         },
         {
          "loss": 0.0006403685547411442,
          "step": 511
         },
         {
          "loss": 0.0003043118922505528,
          "step": 512
         },
         {
          "loss": 0.0002739255432970822,
          "step": 513
         },
         {
          "loss": 0.0004900972126051784,
          "step": 514
         },
         {
          "loss": 0.0005667448276653886,
          "step": 515
         },
         {
          "loss": 0.0009534966084174812,
          "step": 516
         },
         {
          "loss": 0.0018320715753361583,
          "step": 517
         },
         {
          "loss": 0.0013936072355136275,
          "step": 518
         },
         {
          "loss": 0.0002628905058372766,
          "step": 519
         },
         {
          "loss": 0.00030094373505562544,
          "step": 520
         },
         {
          "loss": 0.00034200167283415794,
          "step": 521
         },
         {
          "loss": 0.00021120259771123528,
          "step": 522
         },
         {
          "loss": 0.0005983341834507883,
          "step": 523
         },
         {
          "loss": 0.00029383462970145047,
          "step": 524
         },
         {
          "loss": 0.00026916820206679404,
          "step": 525
         },
         {
          "loss": 0.0004586969153024256,
          "step": 526
         },
         {
          "loss": 0.0003269761800765991,
          "step": 527
         },
         {
          "loss": 0.00034055806463584304,
          "step": 528
         },
         {
          "loss": 0.0012224001111462712,
          "step": 529
         },
         {
          "loss": 0.005575014278292656,
          "step": 530
         },
         {
          "loss": 0.00027748270076699555,
          "step": 531
         },
         {
          "loss": 0.0007429856923408806,
          "step": 532
         },
         {
          "loss": 0.0005500312545336783,
          "step": 533
         },
         {
          "loss": 0.0016513628652319312,
          "step": 534
         },
         {
          "loss": 0.0001991625176742673,
          "step": 535
         },
         {
          "loss": 0.0007457133615389466,
          "step": 536
         },
         {
          "loss": 0.0005693662096746266,
          "step": 537
         },
         {
          "loss": 0.0015688585117459297,
          "step": 538
         },
         {
          "loss": 0.0002033726341323927,
          "step": 539
         },
         {
          "loss": 0.0022237487137317657,
          "step": 540
         },
         {
          "loss": 0.0014588026097044349,
          "step": 541
         },
         {
          "loss": 0.0017796660540625453,
          "step": 542
         },
         {
          "loss": 0.0004862033820245415,
          "step": 543
         },
         {
          "loss": 0.007824096828699112,
          "step": 544
         },
         {
          "loss": 0.002311697695404291,
          "step": 545
         },
         {
          "loss": 0.0008144050952978432,
          "step": 546
         },
         {
          "loss": 0.0003335745132062584,
          "step": 547
         },
         {
          "loss": 0.00028484908398240805,
          "step": 548
         },
         {
          "loss": 0.00017759465845301747,
          "step": 549
         },
         {
          "loss": 0.0007427169475704432,
          "step": 550
         },
         {
          "loss": 0.0002969251945614815,
          "step": 551
         },
         {
          "loss": 0.0005335810710676014,
          "step": 552
         },
         {
          "loss": 0.0003772562195081264,
          "step": 553
         },
         {
          "loss": 0.0010714633390307426,
          "step": 554
         },
         {
          "loss": 0.0010143393883481622,
          "step": 555
         },
         {
          "loss": 0.0011301994090899825,
          "step": 556
         },
         {
          "loss": 0.0006147486856207252,
          "step": 557
         },
         {
          "loss": 0.00025874972925521433,
          "step": 558
         },
         {
          "loss": 5.3716252295998856e-05,
          "step": 559
         },
         {
          "loss": 0.00027775191119872034,
          "step": 560
         },
         {
          "loss": 0.0002641892642714083,
          "step": 561
         },
         {
          "loss": 0.00023532377963420004,
          "step": 562
         },
         {
          "loss": 0.0002160875592380762,
          "step": 563
         },
         {
          "loss": 0.00019361682643648237,
          "step": 564
         },
         {
          "loss": 0.002282604807987809,
          "step": 565
         },
         {
          "loss": 0.00028976876637898386,
          "step": 566
         },
         {
          "loss": 0.0006521655595861375,
          "step": 567
         },
         {
          "loss": 0.0006427722400985658,
          "step": 568
         },
         {
          "loss": 0.00068323576124385,
          "step": 569
         },
         {
          "loss": 0.00022154167527332902,
          "step": 570
         },
         {
          "loss": 0.0018884448800235987,
          "step": 571
         },
         {
          "loss": 0.00020670006051659584,
          "step": 572
         },
         {
          "loss": 0.00023269026132766157,
          "step": 573
         },
         {
          "loss": 0.0012339964741840959,
          "step": 574
         },
         {
          "loss": 0.0009847611654549837,
          "step": 575
         },
         {
          "loss": 0.0010386797366663814,
          "step": 576
         },
         {
          "loss": 0.00020928667800035328,
          "step": 577
         },
         {
          "loss": 0.0008170217624865472,
          "step": 578
         },
         {
          "loss": 0.0016137767815962434,
          "step": 579
         },
         {
          "loss": 0.00014875851047690958,
          "step": 580
         },
         {
          "loss": 0.0006472872919403017,
          "step": 581
         },
         {
          "loss": 0.0005630074883811176,
          "step": 582
         },
         {
          "loss": 0.00020433533063624054,
          "step": 583
         },
         {
          "loss": 0.00022334206732921302,
          "step": 584
         },
         {
          "loss": 0.0002455479698255658,
          "step": 585
         },
         {
          "loss": 0.00033054922823794186,
          "step": 586
         },
         {
          "loss": 0.00013244597357697785,
          "step": 587
         },
         {
          "loss": 0.00018429651390761137,
          "step": 588
         },
         {
          "loss": 0.0004355594574008137,
          "step": 589
         },
         {
          "loss": 0.00037575606256723404,
          "step": 590
         },
         {
          "loss": 0.00023991058696992695,
          "step": 591
         },
         {
          "loss": 0.0003586385282687843,
          "step": 592
         },
         {
          "loss": 0.007165907416492701,
          "step": 593
         },
         {
          "loss": 0.00021421340352389961,
          "step": 594
         },
         {
          "loss": 0.00024758296785876155,
          "step": 595
         },
         {
          "loss": 0.00032345220097340643,
          "step": 596
         },
         {
          "loss": 0.0003794440417550504,
          "step": 597
         },
         {
          "loss": 0.0010023864451795816,
          "step": 598
         },
         {
          "loss": 1.545574195915833e-05,
          "step": 599
         },
         {
          "loss": 0.00022069514670874923,
          "step": 600
         },
         {
          "loss": 0.000832218793220818,
          "step": 601
         },
         {
          "loss": 0.00021971989190205932,
          "step": 602
         },
         {
          "loss": 0.0003644151147454977,
          "step": 603
         },
         {
          "loss": 0.00037830020301043987,
          "step": 604
         },
         {
          "loss": 0.0002756800677161664,
          "step": 605
         },
         {
          "loss": 0.00020297314040362835,
          "step": 606
         },
         {
          "loss": 0.00021889891650062054,
          "step": 607
         },
         {
          "loss": 0.0019941984210163355,
          "step": 608
         },
         {
          "loss": 0.0007304890314117074,
          "step": 609
         },
         {
          "loss": 0.00016326943296007812,
          "step": 610
         },
         {
          "loss": 0.00015511774108745158,
          "step": 611
         },
         {
          "loss": 0.0003137130697723478,
          "step": 612
         },
         {
          "loss": 0.004124619998037815,
          "step": 613
         },
         {
          "loss": 0.0008145839092321694,
          "step": 614
         },
         {
          "loss": 0.0007005989318713546,
          "step": 615
         },
         {
          "loss": 0.00024426981690339744,
          "step": 616
         },
         {
          "loss": 0.00023378946934826672,
          "step": 617
         },
         {
          "loss": 0.00019491446437314153,
          "step": 618
         },
         {
          "loss": 0.0004892502911388874,
          "step": 619
         },
         {
          "loss": 0.00021113359252922237,
          "step": 620
         },
         {
          "loss": 0.00021250547433737665,
          "step": 621
         },
         {
          "loss": 0.00015907423221506178,
          "step": 622
         },
         {
          "loss": 0.0001750572118908167,
          "step": 623
         },
         {
          "loss": 0.0014834681060165167,
          "step": 624
         },
         {
          "loss": 0.0001787431538105011,
          "step": 625
         },
         {
          "loss": 0.00019415965653024614,
          "step": 626
         },
         {
          "loss": 0.00020274687267374247,
          "step": 627
         },
         {
          "loss": 0.00014446390559896827,
          "step": 628
         },
         {
          "loss": 0.0001879744086181745,
          "step": 629
         },
         {
          "loss": 0.0010076432954519987,
          "step": 630
         },
         {
          "loss": 0.00016598300135228783,
          "step": 631
         },
         {
          "loss": 0.0017710333922877908,
          "step": 632
         },
         {
          "loss": 0.0007947031990624964,
          "step": 633
         },
         {
          "loss": 0.00025772611843422055,
          "step": 634
         },
         {
          "loss": 0.0001181784100481309,
          "step": 635
         },
         {
          "loss": 0.0004916383768431842,
          "step": 636
         },
         {
          "loss": 0.0011053828056901693,
          "step": 637
         },
         {
          "loss": 0.00032962067052721977,
          "step": 638
         },
         {
          "loss": 7.480483327526599e-05,
          "step": 639
         },
         {
          "loss": 0.001883431919850409,
          "step": 640
         },
         {
          "loss": 0.00348893110640347,
          "step": 641
         },
         {
          "loss": 0.0001781978935468942,
          "step": 642
         },
         {
          "loss": 0.00014468126755673438,
          "step": 643
         },
         {
          "loss": 0.00013195355131756514,
          "step": 644
         },
         {
          "loss": 0.00018572334374766797,
          "step": 645
         },
         {
          "loss": 0.0003784658620133996,
          "step": 646
         },
         {
          "loss": 0.0006383520667441189,
          "step": 647
         },
         {
          "loss": 0.00013019880861975253,
          "step": 648
         },
         {
          "loss": 0.0007769042858853936,
          "step": 649
         },
         {
          "loss": 0.0006802276475355029,
          "step": 650
         },
         {
          "loss": 0.00018652847211342305,
          "step": 651
         },
         {
          "loss": 0.00046380251296795905,
          "step": 652
         },
         {
          "loss": 0.00015998246090020984,
          "step": 653
         },
         {
          "loss": 0.0001121206660172902,
          "step": 654
         },
         {
          "loss": 0.00014696539437863976,
          "step": 655
         },
         {
          "loss": 0.0001476388715673238,
          "step": 656
         },
         {
          "loss": 0.00044675011304207146,
          "step": 657
         },
         {
          "loss": 0.0013696957612410188,
          "step": 658
         },
         {
          "loss": 0.00013659744581673294,
          "step": 659
         },
         {
          "loss": 0.00028098872280679643,
          "step": 660
         },
         {
          "loss": 0.0004628058522939682,
          "step": 661
         },
         {
          "loss": 0.0004001532506663352,
          "step": 662
         },
         {
          "loss": 0.0015609510010108352,
          "step": 663
         },
         {
          "loss": 0.00010809522063937038,
          "step": 664
         },
         {
          "loss": 0.0002259027969557792,
          "step": 665
         },
         {
          "loss": 0.00013802126341033727,
          "step": 666
         },
         {
          "loss": 0.00022476978483609855,
          "step": 667
         },
         {
          "loss": 0.0002701061312109232,
          "step": 668
         },
         {
          "loss": 0.00025717244716361165,
          "step": 669
         },
         {
          "loss": 0.00023626419715583324,
          "step": 670
         },
         {
          "loss": 0.0002469010360073298,
          "step": 671
         },
         {
          "loss": 0.0010485299862921238,
          "step": 672
         },
         {
          "loss": 0.00018270187138114125,
          "step": 673
         },
         {
          "loss": 0.0006667844136245549,
          "step": 674
         },
         {
          "loss": 0.0003228436107747257,
          "step": 675
         },
         {
          "loss": 0.0002577075210865587,
          "step": 676
         },
         {
          "loss": 0.0005249034729786217,
          "step": 677
         },
         {
          "loss": 0.00019341132428962737,
          "step": 678
         },
         {
          "loss": 0.00015962707402650267,
          "step": 679
         },
         {
          "loss": 0.00032677530543878675,
          "step": 680
         },
         {
          "loss": 0.0008074002107605338,
          "step": 681
         },
         {
          "loss": 0.000398694392060861,
          "step": 682
         },
         {
          "loss": 0.00017403213132638484,
          "step": 683
         },
         {
          "loss": 0.00048018665984272957,
          "step": 684
         },
         {
          "loss": 8.359739149454981e-05,
          "step": 685
         },
         {
          "loss": 0.00018145219655707479,
          "step": 686
         },
         {
          "loss": 0.00012240266369190067,
          "step": 687
         },
         {
          "loss": 0.00032301724422723055,
          "step": 688
         },
         {
          "loss": 0.00012104403867851943,
          "step": 689
         },
         {
          "loss": 0.0001359205780318007,
          "step": 690
         },
         {
          "loss": 0.0001807677181204781,
          "step": 691
         },
         {
          "loss": 0.00010529551218496636,
          "step": 692
         },
         {
          "loss": 0.007387954741716385,
          "step": 693
         },
         {
          "loss": 0.00016796583076938987,
          "step": 694
         },
         {
          "loss": 0.0001354869018541649,
          "step": 695
         },
         {
          "loss": 0.002706552855670452,
          "step": 696
         },
         {
          "loss": 0.00016379181761294603,
          "step": 697
         },
         {
          "loss": 0.00022868321684654802,
          "step": 698
         },
         {
          "loss": 0.0003396823594812304,
          "step": 699
         },
         {
          "loss": 0.0001669517660047859,
          "step": 700
         },
         {
          "loss": 0.00030651266570203006,
          "step": 701
         },
         {
          "loss": 8.623640314908698e-05,
          "step": 702
         },
         {
          "loss": 0.001150343450717628,
          "step": 703
         },
         {
          "loss": 0.00014791758439969271,
          "step": 704
         },
         {
          "loss": 0.00014378430205397308,
          "step": 705
         },
         {
          "loss": 0.00019241565314587206,
          "step": 706
         },
         {
          "loss": 0.00013333119568414986,
          "step": 707
         },
         {
          "loss": 0.00019407026411499828,
          "step": 708
         },
         {
          "loss": 0.00012771194451488554,
          "step": 709
         },
         {
          "loss": 0.0006774267531000078,
          "step": 710
         },
         {
          "loss": 0.0001699712302070111,
          "step": 711
         },
         {
          "loss": 0.0002560810826253146,
          "step": 712
         },
         {
          "loss": 0.00021496742556337267,
          "step": 713
         },
         {
          "loss": 0.0007308334461413324,
          "step": 714
         },
         {
          "loss": 0.000369595130905509,
          "step": 715
         },
         {
          "loss": 0.0006936920108273625,
          "step": 716
         },
         {
          "loss": 0.0001155785794253461,
          "step": 717
         },
         {
          "loss": 0.00010268686310155317,
          "step": 718
         },
         {
          "loss": 1.608113780093845e-05,
          "step": 719
         },
         {
          "loss": 0.0014914480270817876,
          "step": 720
         },
         {
          "loss": 0.000163870703545399,
          "step": 721
         },
         {
          "loss": 0.00010605675197439268,
          "step": 722
         },
         {
          "loss": 0.00021139012824278325,
          "step": 723
         },
         {
          "loss": 9.969215170713142e-05,
          "step": 724
         },
         {
          "loss": 0.00011961732525378466,
          "step": 725
         },
         {
          "loss": 0.00040426189661957324,
          "step": 726
         },
         {
          "loss": 0.0002147936902474612,
          "step": 727
         },
         {
          "loss": 0.00013354953262023628,
          "step": 728
         },
         {
          "loss": 0.0002490956976544112,
          "step": 729
         },
         {
          "loss": 9.770833275979385e-05,
          "step": 730
         },
         {
          "loss": 0.0004397861484903842,
          "step": 731
         },
         {
          "loss": 0.0001826059160521254,
          "step": 732
         },
         {
          "loss": 0.00012465381587389857,
          "step": 733
         },
         {
          "loss": 0.0014835209585726261,
          "step": 734
         },
         {
          "loss": 8.270247053587809e-05,
          "step": 735
         },
         {
          "loss": 5.5253411119338125e-05,
          "step": 736
         },
         {
          "loss": 0.00011050551984226331,
          "step": 737
         },
         {
          "loss": 0.00029988979804329574,
          "step": 738
         },
         {
          "loss": 0.000523654802236706,
          "step": 739
         },
         {
          "loss": 0.00019902116036973894,
          "step": 740
         },
         {
          "loss": 0.00012452747614588588,
          "step": 741
         },
         {
          "loss": 9.240200597560033e-05,
          "step": 742
         },
         {
          "loss": 9.276458149543032e-05,
          "step": 743
         },
         {
          "loss": 0.00033759427606128156,
          "step": 744
         },
         {
          "loss": 9.02915999176912e-05,
          "step": 745
         },
         {
          "loss": 0.0005512401694431901,
          "step": 746
         },
         {
          "loss": 9.912465611705557e-05,
          "step": 747
         },
         {
          "loss": 9.52520058490336e-05,
          "step": 748
         },
         {
          "loss": 0.0002159535069949925,
          "step": 749
         },
         {
          "loss": 9.762565605342388e-05,
          "step": 750
         },
         {
          "loss": 0.0014475707430392504,
          "step": 751
         },
         {
          "loss": 0.004527966491878033,
          "step": 752
         },
         {
          "loss": 8.494513167534024e-05,
          "step": 753
         },
         {
          "loss": 0.00011465598072391003,
          "step": 754
         },
         {
          "loss": 9.073757246369496e-05,
          "step": 755
         },
         {
          "loss": 0.0010061797220259905,
          "step": 756
         },
         {
          "loss": 7.782891043461859e-05,
          "step": 757
         },
         {
          "loss": 0.00037267457810230553,
          "step": 758
         },
         {
          "loss": 3.438947896938771e-05,
          "step": 759
         },
         {
          "loss": 0.00010152167669730261,
          "step": 760
         },
         {
          "loss": 0.00025817539426498115,
          "step": 761
         },
         {
          "loss": 0.00016302868607454002,
          "step": 762
         },
         {
          "loss": 0.0002666447253432125,
          "step": 763
         },
         {
          "loss": 0.0001302641467191279,
          "step": 764
         },
         {
          "loss": 0.00015775208885315806,
          "step": 765
         },
         {
          "loss": 0.0009843410225585103,
          "step": 766
         },
         {
          "loss": 8.49782518344e-05,
          "step": 767
         },
         {
          "loss": 0.00013104485697112978,
          "step": 768
         },
         {
          "loss": 0.00011515829828567803,
          "step": 769
         },
         {
          "loss": 0.0002483153948560357,
          "step": 770
         },
         {
          "loss": 0.00010083645611302927,
          "step": 771
         },
         {
          "loss": 0.00017059080710168928,
          "step": 772
         },
         {
          "loss": 8.273480489151552e-05,
          "step": 773
         },
         {
          "loss": 8.208244253182784e-05,
          "step": 774
         },
         {
          "loss": 0.0003433885285630822,
          "step": 775
         },
         {
          "loss": 0.0007799143786542118,
          "step": 776
         },
         {
          "loss": 0.0001015805100905709,
          "step": 777
         },
         {
          "loss": 0.00045625361963175237,
          "step": 778
         },
         {
          "loss": 0.00022089378035161644,
          "step": 779
         },
         {
          "loss": 9.420805145055056e-05,
          "step": 780
         },
         {
          "loss": 0.00010342552559450269,
          "step": 781
         },
         {
          "loss": 4.150619497522712e-05,
          "step": 782
         },
         {
          "loss": 0.00032552864286117256,
          "step": 783
         },
         {
          "loss": 5.076808884041384e-05,
          "step": 784
         },
         {
          "loss": 0.000600010680500418,
          "step": 785
         },
         {
          "loss": 0.00035401401692070067,
          "step": 786
         },
         {
          "loss": 0.0001059945352608338,
          "step": 787
         },
         {
          "loss": 0.00010032878344645724,
          "step": 788
         },
         {
          "loss": 0.00035986927105113864,
          "step": 789
         },
         {
          "loss": 9.726100688567385e-05,
          "step": 790
         },
         {
          "loss": 0.0002564572496339679,
          "step": 791
         },
         {
          "loss": 0.00019854935817420483,
          "step": 792
         },
         {
          "loss": 0.00015252993034664541,
          "step": 793
         },
         {
          "loss": 0.0032949906308203936,
          "step": 794
         },
         {
          "loss": 7.087412814144045e-05,
          "step": 795
         },
         {
          "loss": 9.807499736780301e-05,
          "step": 796
         },
         {
          "loss": 0.0005588826606981456,
          "step": 797
         },
         {
          "loss": 9.880933066597208e-05,
          "step": 798
         },
         {
          "loss": 8.543612784706056e-05,
          "step": 799
         }
        ]
       },
       "encoding": {
        "x": {
         "field": "step",
         "scale": {},
         "type": "quantitative"
        },
        "y": {
         "field": "loss",
         "scale": {
          "type": "log"
         },
         "type": "quantitative"
        }
       },
       "height": 400,
       "mark": "line",
       "width": 800
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas\n",
    "\n",
    "batch_loss = []\n",
    "for i,l in enumerate(train_losses):\n",
    "    batch_loss.append((i,l))\n",
    "\n",
    "df = pandas.DataFrame(batch_loss, columns=['step', 'loss'])\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    alt.X('step', scale=alt.Scale()),\n",
    "    alt.Y('loss', scale=alt.Scale(type='log'))).properties(\n",
    "        width=800,\n",
    "        height=400\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efabb0156cc14bbbb0f3e05ce6817fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a98b4618d73413cbb2aa163b7db0c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positive training samples : 12500 \n",
      "Negaitve training samples : 12500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea04454fc96405bb28982b9aeccc378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be4cdece99b4fac818b68d2d3be5bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    result_list = []\n",
    "    for l in input_list:\n",
    "        result_list.append([list(zip(*[l[i:] for i in range(n)])), ' '.join(l)])\n",
    "    return result_list\n",
    "\n",
    "# get the training data\n",
    "TEST_FILES_POS = glob('/home/kulikov/vlgwork/aclImdb/test/pos/*')\n",
    "pos_test_texts = []\n",
    "TEST_FILES_NEG = glob('/home/kulikov/vlgwork/aclImdb/test/neg/*')\n",
    "neg_test_texts = []\n",
    "\n",
    "# get training text in RAM\n",
    "for fname in _tqdm(TEST_FILES_NEG):\n",
    "    with open(fname, 'r') as f:\n",
    "        neg_test_texts.append(f.read())\n",
    "for fname in _tqdm(TEST_FILES_POS):\n",
    "    with open(fname, 'r') as f:\n",
    "        pos_test_texts.append(f.read())\n",
    "        \n",
    "print(\"Positive training samples : {} \\nNegaitve training samples : {}\".format(len(pos_test_texts), len(neg_test_texts)))\n",
    "\n",
    "#clean from html tags\n",
    "pos_test_texts = [remove_tags(t) for t in pos_test_texts]\n",
    "neg_test_texts = [remove_tags(t) for t in neg_test_texts]\n",
    "\n",
    "pos_test_texts_toked, n1 =  tokenize_dataset(pos_test_texts)\n",
    "neg_test_texts_toked, n2 =  tokenize_dataset(neg_test_texts)\n",
    "\n",
    "test_data = {'pos': find_ngrams(pos_test_texts_toked, NGRAM),\n",
    "              'neg': find_ngrams(neg_test_texts_toked, NGRAM)}\n",
    "\n",
    "test_data_id = {}\n",
    "test_data_id['pos'] = []\n",
    "for d in test_data['pos']:\n",
    "    test_data_id['pos'].append([_text2id(d[0]), d[1]])\n",
    "    \n",
    "test_data_id['neg'] = []\n",
    "for d in test_data['neg']:\n",
    "    test_data_id['neg'].append([_text2id(d[0]), d[1]])\n",
    "    \n",
    "test_data_id_merged = []\n",
    "\n",
    "for d in test_data_id['pos']:\n",
    "    test_data_id_merged.append((d[0], 0, d[1]))\n",
    "for d in test_data_id['neg']:\n",
    "    test_data_id_merged.append((d[0], 1, d[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbDatasetWithText(Dataset):\n",
    "    def __init__(self, data_list, max_inp_length=None, device='cpu'):\n",
    "        \"\"\"\n",
    "        data_list is a list of tuples: (x,y) where x is a list of ids and y is a label\n",
    "        \"\"\"\n",
    "        self.data = data_list\n",
    "        self.max_len = max_inp_length\n",
    "        self.data_tensors = []\n",
    "        self.text = []\n",
    "        for (i, t, text) in tqdm_notebook(self.data):\n",
    "            self.data_tensors.append((torch.LongTensor(i[:self.max_len]).to(device), torch.LongTensor([t]).to(device)))\n",
    "            self.text.append(text)\n",
    "              \n",
    "    def __getitem__(self, key):\n",
    "        (inp, tgt) = self.data_tensors[key]\n",
    "        text = self.text[key]\n",
    "        \n",
    "        return inp, tgt, len(inp), text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def pad(tensor, length, dim=0, pad=0):\n",
    "    \"\"\"Pad tensor to a specific length.\n",
    "    :param tensor: vector to pad\n",
    "    :param length: new length\n",
    "    :param dim: (default 0) dimension to pad\n",
    "    :returns: padded tensor if the tensor is shorter than length\n",
    "    \"\"\"\n",
    "    if tensor.size(dim) < length:\n",
    "        return torch.cat(\n",
    "            [tensor, tensor.new(*tensor.size()[:dim],\n",
    "                                length - tensor.size(dim),\n",
    "                                *tensor.size()[dim + 1:]).fill_(pad)],\n",
    "            dim=dim)\n",
    "    else:\n",
    "        return tensor\n",
    "    \n",
    "def batchify(batch):\n",
    "    maxlen = max(batch, key = itemgetter(2))[-2]\n",
    "    batch_list = []\n",
    "    target_list = []\n",
    "    text_list = []\n",
    "    for b in batch:\n",
    "        batch_list.append(pad(b[0], maxlen, dim=0, pad=PAD_IDX))\n",
    "        target_list.append(b[1])\n",
    "        text_list.append(b[3])\n",
    "    input_batch = torch.stack(batch_list, 0)\n",
    "    target_batch = torch.stack(target_list, 0)\n",
    "    \n",
    "    return input_batch, target_batch, text_list\n",
    "\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, labels, text in loader:\n",
    "        outputs = torch.sigmoid(model(data))\n",
    "        predicted = (outputs > 0.5).long()\n",
    "        #import ipdb; ipdb.set_trace() # use this to get examples below\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1eb8c5d745041158daede65bcdef950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ImdbDatasetWithText(test_data_id_merged, max_inp_length=None, device='cuda')\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, collate_fn=batchify, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.856"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(loader=test_loader, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correctly predicted samples\n",
    "\n",
    "### Positive\n",
    "`it 's hard to know what to make of this weird little aussie crime flick on the one hand it 's an enjoyable little film with a great sense of humour but on the other it just lacks a certain something that ensures the film never reaches above it 's boundary that keeps it trapped within the merely interesting territory that being said two hands is a well plotted film that excellently juggles several stories at the same time which allows several small climaxes throughout the movie and that in turn helps to stop the film becoming boring the absurdity of the goings on the thick australian accents and the bizarre set of characters all help to ensure that the film entertains also the plot follows the story of a young doorman who thinks he 'll go on to bigger things after accepting a job from the local kingpin he does n't the job only lands him in trouble when he fancies a swim and stupidly leaves ten grand on the beach which is promptly stolen by a couple of kids who have the time of their lives on a shopping spree however all is not rosy for our hero who must find the money or face the consequences ... the film is made up of a cast of unknowns at least it was back in 1999 as nowadays heath ledger is something of a name he does n't impress too much here however as his performance is mostly of the one note variety and he does n't make for a very compelling lead he fits the movie in that he 's australian and looks naive but beyond that he 's not the best lead i 've ever seen in a movie if you ask me bryan brown gave the best performance here he might not have a great deal of screen time but he steals every scene he 's in and it 's him that provides the movie with a lot of its humour he 's got nothing to do with the best sequence however which takes place in the form of probably the most hilarious bank robbery ever caught on film on the whole i can recommend this film to people that enjoy quirky crime films as the weirdness is plentiful and the way that events take a turn for the bizarre is enjoyable but if you 're not a fan of this sort of film i ca n't really say that two hands will float your boat it 's not a must see but if it 's your thing and you get a chance to see it ... you probably wo nt completely regret it`\n",
    "\n",
    "### Positive\n",
    "`sally and saint anne is a very funny movie the first time my mom told me about it i was 7 and saint anne had just been the saint i had for my communion saint my mom knew this so she told me to watch this with her i did and have seen it many times since because it is really funny aunt bea from the andy griffith show was in it and sally 's grandfather was the guy who played santa claus in miracle on 34th street so there were lots of actors we seen on tv shows too there is a bad guy who keeps trying to steal the house away and sally keeps trying things with st. anne to help raise money so they can keep the house that includes a boxing match with hugh o'brian who plays her older brother this is a good and funny movie that i still love`\n",
    "\n",
    "### Negative\n",
    "`unless there 's some huge ironic conspiracy going on my jaw dropped when i read the positive reviews of this film i can not believe that this film was even released it 's so bad i admit it is not my kind of movie but i tried to watch it objectively anyway you know so bad it 's funny and was still offended at its sheer awfulness the acting is atrocious they ca n't have watched the rushes and i 'm guessing there was one take per scene it really is that terrible it is the worst film i have seen in many a year in fact i would n't even call it a film it 's a tragedy the gay black friend whom no one actually calls gay it 's just implied because he 's so crazy homophobic this is not good in fact this is downright vomit inducing the jokes die on their pathetic arses the music is so bad it defies belief the person who compiled the soundtrack essentially chose the most ear mutilatingly bad songs they had ever heard and put them in this waste of film stock oh my good christ i ca n't believe the 80 's produced utter garbage like this i grew up through them and i can not find one thing worth of note here it must have been a dark time to be a cinema goer if you even contemplate watching this film go see a psychiatrist he will then accordingly slap you you sick sick person`\n",
    "\n",
    "## incorrectly predicted samples\n",
    "\n",
    "### Positive (predicted as negative)\n",
    "`ok when i rented this several years ago i had the worst expectations yes the acting is n't great and the picture itself looks dated but as i sat there a strange thing happened i started to like it the action is great and there are few scenes that make you jump brion james maybe one of the greatest b grade actors next to bruce campbell is great as always the story is n't bad either now i would n't rush out and buy it but you wo n't waste your time at least watching this good b grade post apocalyptic western`\n",
    "\n",
    "### Negative (predicted as positive)\n",
    "`i first saw this movie at a saturday matinee when i was very young i thought it was cool and often thought about it well i finally resaw it on dvd it was still very entertaining but in a different way it has to rank as one of the goofiest campiest 1950 's sci fi movies it seemed filled with stock military footage the dialogue is stilted and effects are crude there is one line of dialogue that had me in stitches the line jeff morrow says while on the beach with the babe rent it if you need a movie to watch with a bunch of drunken friends it is a classic`\n",
    "\n",
    "### Positive (predicted as negative)\n",
    "`look ... i\\'ve come to expect this level of acting from william macy ... the guy just keeps putting in terrific performances ... but meat loaf just when did his loafness decide to leave jim steinman behind and throw his decidedly lower weight around in the wonderful world of stanislavsky well ... what can i say i \\'m duly impressed to paraphrase an old adage it ai n\\'t the meat it \\'s the emotion\" ... and the loaf is quietly buffing up his acting chops of late .. laura dern carries off the 40 \\'s look perfectly here ... great job by the costume and hair departments ... david paymer is typecast but right on the money solid camera work throughout the flick the plot line is reminiscent of gentleman \\'s agreement post wwii anti semitism well worth your time ... particularly for the growing legions of bill macy acolytes`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
