{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use textacy which is a lib on top of spacy to do some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: more_itertools in /misc/vlgscratch4/ChoGroup/kulikov/venv/parlai/lib/python3.6/site-packages (4.3.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.0.0 in /misc/vlgscratch4/ChoGroup/kulikov/venv/parlai/lib/python3.6/site-packages/six-1.11.0-py3.6.egg (from more_itertools) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "# run if you dont have it installed\n",
    "!pip install more_itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next cell is loading the training data disregarding NGRAM size and max vocabulary/max seq len size, it needs to be run only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e867e9dd13b4ce499d5d75b8b9d5dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50333dd61acd4f31ae5fa98c61b9b0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive training samples : 12500 \n",
      "Negaitve training samples : 12500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a966dc41dda4a0db4f4cf1efe21a4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633228dcb561417a9456346e126f147e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ee5d48337c42d1a8e3e0294b11d956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f14806deef44e2acc11f1250c2a044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocabulary size: 92929 words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5bdd7b90204c7fa7003ff98ecb29b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a794c48462433391a9675cb4d82e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive training samples : 12500 \n",
      "Negaitve training samples : 12500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4430199c36d45219eae3abae323ecf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4335148766ec4e63ac4ee6e60ce1a561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy\n",
    "import itertools\n",
    "from operator import itemgetter \n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "import re\n",
    "import more_itertools as mit  # not built-in package\n",
    "_tqdm = tqdm_notebook  # prolly you need jupyter widget for this, change for tqdm for simple tqdm\n",
    "\n",
    "# get the training data\n",
    "TRAIN_FILES_POS = glob('/home/kulikov/vlgwork/aclImdb/train/pos/*')\n",
    "pos_train_texts = []\n",
    "TRAIN_FILES_NEG = glob('/home/kulikov/vlgwork/aclImdb/train/neg/*')\n",
    "neg_train_texts = []\n",
    "\n",
    "# get training text in RAM\n",
    "for fname in _tqdm(TRAIN_FILES_NEG):\n",
    "    with open(fname, 'r') as f:\n",
    "        neg_train_texts.append(f.read())\n",
    "for fname in _tqdm(TRAIN_FILES_POS):\n",
    "    with open(fname, 'r') as f:\n",
    "        pos_train_texts.append(f.read())\n",
    "        \n",
    "print(\"Positive training samples : {} \\nNegaitve training samples : {}\".format(len(pos_train_texts), len(neg_train_texts)))\n",
    "\n",
    "TRAIN_SIZE=10000  # change this if you want\n",
    "                       \n",
    "# Split training data on train valid parts now\n",
    "pos_valid_texts = pos_train_texts[TRAIN_SIZE:]\n",
    "pos_train_texts = pos_train_texts[:TRAIN_SIZE]\n",
    "neg_valid_texts = neg_train_texts[TRAIN_SIZE:]\n",
    "neg_train_texts = neg_train_texts[:TRAIN_SIZE]\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "TAG_RE = re.compile(r'<[^>]+>') # get rid off HTML tags from the data\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def lower_case_remove_punc(parsed):\n",
    "    return [token.text.lower() for token in parsed if (token.text not in punctuations)] #and (token.is_stop is False)]\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    token_dataset = []\n",
    "    # we are keeping track of all tokens in dataset \n",
    "    # in order to create vocabulary later\n",
    "    all_tokens = []\n",
    "\n",
    "    for sample in _tqdm(tokenizer.pipe(dataset, disable=['parser', 'tagger', 'ner'], batch_size=512, n_threads=1)):\n",
    "        tokens = lower_case_remove_punc(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "        \n",
    "    return token_dataset, all_tokens\n",
    "                       \n",
    "#clean from html tags\n",
    "pos_valid_texts = [remove_tags(t) for t in pos_valid_texts]\n",
    "neg_valid_texts = [remove_tags(t) for t in neg_valid_texts]\n",
    "pos_train_texts = [remove_tags(t) for t in pos_train_texts]\n",
    "neg_train_texts = [remove_tags(t) for t in neg_train_texts]\n",
    "\n",
    "pos_valid_texts_toked, n1 =  tokenize_dataset(pos_valid_texts)\n",
    "neg_valid_texts_toked, n2 =  tokenize_dataset(neg_valid_texts)\n",
    "pos_train_texts_toked, n3 =  tokenize_dataset(pos_train_texts)\n",
    "neg_train_texts_toked, n4 =  tokenize_dataset(neg_train_texts)\n",
    "                       \n",
    "voc = list(set(n1 + n2 + n3 + n4))\n",
    "print('Word vocabulary size: {} words'.format(len(voc)))\n",
    "\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "# get the test data\n",
    "TEST_FILES_POS = glob('/home/kulikov/vlgwork/aclImdb/test/pos/*')\n",
    "pos_test_texts = []\n",
    "TEST_FILES_NEG = glob('/home/kulikov/vlgwork/aclImdb/test/neg/*')\n",
    "neg_test_texts = []\n",
    "\n",
    "# get training text in RAM\n",
    "for fname in _tqdm(TEST_FILES_NEG):\n",
    "    with open(fname, 'r') as f:\n",
    "        neg_test_texts.append(f.read())\n",
    "for fname in _tqdm(TEST_FILES_POS):\n",
    "    with open(fname, 'r') as f:\n",
    "        pos_test_texts.append(f.read())\n",
    "\n",
    "print(\"Positive training samples : {} \\nNegaitve training samples : {}\".format(len(pos_test_texts), len(neg_test_texts)))\n",
    "\n",
    "#clean from html tags\n",
    "pos_test_texts = [remove_tags(t) for t in pos_test_texts]\n",
    "neg_test_texts = [remove_tags(t) for t in neg_test_texts]\n",
    "\n",
    "pos_test_texts_toked, n1 =  tokenize_dataset(pos_test_texts)\n",
    "neg_test_texts_toked, n2 =  tokenize_dataset(neg_test_texts)\n",
    "\n",
    "\n",
    "\n",
    "def find_ngrams(input_list, n):\n",
    "    result_list = []\n",
    "    for l in input_list:\n",
    "        result_list.append(list(zip(*[l[i:] for i in range(n)])))\n",
    "    return result_list\n",
    "\n",
    "class ImdbDataset(Dataset):\n",
    "    def __init__(self, data_list, max_inp_length=None, device='cpu'):\n",
    "        \"\"\"\n",
    "        data_list is a list of tuples: (x,y) where x is a list of ids and y is a label\n",
    "        \"\"\"\n",
    "        self.data = data_list\n",
    "        self.max_len = max_inp_length\n",
    "        self.data_tensors = []\n",
    "        for (i, t) in tqdm_notebook(self.data):\n",
    "            \n",
    "            self.data_tensors.append((torch.LongTensor(i[:self.max_len]).to(device), torch.LongTensor([t]).to(device)))\n",
    "              \n",
    "    def __getitem__(self, key):\n",
    "        (inp, tgt) = self.data_tensors[key]\n",
    "        \n",
    "        return inp, tgt, len(inp)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def pad(tensor, length, dim=0, pad=0):\n",
    "    \"\"\"Pad tensor to a specific length.\n",
    "    :param tensor: vector to pad\n",
    "    :param length: new length\n",
    "    :param dim: (default 0) dimension to pad\n",
    "    :returns: padded tensor if the tensor is shorter than length\n",
    "    \"\"\"\n",
    "    if tensor.size(dim) < length:\n",
    "        return torch.cat(\n",
    "            [tensor, tensor.new(*tensor.size()[:dim],\n",
    "                                length - tensor.size(dim),\n",
    "                                *tensor.size()[dim + 1:]).fill_(pad)],\n",
    "            dim=dim)\n",
    "    else:\n",
    "        return tensor\n",
    "    \n",
    "def batchify(batch):\n",
    "    maxlen = max(batch, key = itemgetter(2))[-1]\n",
    "    batch_list = []\n",
    "    target_list = []\n",
    "    for b in batch:\n",
    "        batch_list.append(pad(b[0], maxlen, dim=0, pad=PAD_IDX))\n",
    "        target_list.append(b[1])\n",
    "    input_batch = torch.stack(batch_list, 0)\n",
    "    target_batch = torch.stack(target_list, 0)\n",
    "    \n",
    "    return input_batch, target_batch\n",
    "\n",
    "class BagOfNGrams(nn.Module):\n",
    "    def init_layers(self):\n",
    "        for l in self.layers:\n",
    "            if getattr(l, 'weight', None) is not None:\n",
    "                torch.nn.init.xavier_uniform_(l.weight)\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_dim=300, hidden_size=512, reduce='sum', nlayers=2, act='ReLU', nclasses=2, dropout=0.1, batch_norm=False):\n",
    "        super(BagOfNGrams, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.reduce = reduce\n",
    "        self.nlayers = nlayers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nclasses = nclasses\n",
    "        self.act = getattr(nn, act)\n",
    "        self.embedding = nn.EmbeddingBag(num_embeddings=vocab_size, embedding_dim=emb_dim, mode=reduce)\n",
    "        if batch_norm is True:\n",
    "            self.batch_norm = nn.BatchNorm1d(self.emb_dim)\n",
    "        #self.layers = nn.ModuleList([nn.Linear(self.emb_dim, 1)])\n",
    "        self.layers = nn.ModuleList([nn.Linear(self.emb_dim, self.hidden_size)])\n",
    "        self.layers.append(self.act())\n",
    "        self.layers.append(nn.Dropout(p=dropout))\n",
    "        for i in range(self.nlayers-2):\n",
    "            self.layers.append(nn.Linear(self.hidden_size, self.hidden_size))\n",
    "            self.layers.append(self.act())\n",
    "            self.layers.append(nn.Dropout(p=dropout))\n",
    "        self.layers.append(nn.Linear(self.hidden_size, 1))\n",
    "        self.init_layers()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        postemb = self.embedding(x)\n",
    "        if hasattr(self, 'batch_norm'):\n",
    "            x = self.batch_norm(postemb)\n",
    "        else:\n",
    "            x = postemb\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "OPTS = {\n",
    "    'lr': [0.001, 0.1],\n",
    "    'batch_size': [512],\n",
    "    'max_voc_size': [1000, 100000],\n",
    "    'context_length': [1,2,3,4],\n",
    "    'max_input_length': [None, 300],\n",
    "    'embedding_size': [30, 300],\n",
    "    'num_epochs': [20],\n",
    "    'optimizer': ['Adam', 'SGD'],\n",
    "    \n",
    "}\n",
    "\n",
    "indp = [[{key: value} for value in values] for key, values in OPTS.items()]\n",
    "product_options = list(itertools.product(*indp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_dicts = []\n",
    "for t in product_options:\n",
    "    prod_dicts.append({ k: v for d in t for k, v in d.items() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train_val(opts):\n",
    "    #print(opts)\n",
    "    NGRAM = opts['context_length']  # change this to make different N grams for each token\n",
    "    # now make train and valid dicts\n",
    "\n",
    "    train_data = {'pos': find_ngrams(pos_train_texts_toked, NGRAM),\n",
    "                  'neg': find_ngrams(neg_train_texts_toked, NGRAM)}\n",
    "    valid_data = {'pos': find_ngrams(pos_valid_texts_toked, NGRAM),\n",
    "                 'neg': find_ngrams(neg_valid_texts_toked, NGRAM)}\n",
    "\n",
    "    max_vocab_size = opts['max_voc_size']\n",
    "    # save index 0 for unk and 1 for pad\n",
    "    PAD_IDX = 0\n",
    "    UNK_IDX = 1\n",
    "\n",
    "    all_train_tokens = list(mit.flatten(train_data['pos'] + train_data['neg'] + valid_data['pos'] + valid_data['neg']))\n",
    "    counted_tokens = Counter(all_train_tokens)\n",
    "\n",
    "    vocab, count = zip(*counted_tokens.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "\n",
    "    # Lets check the dictionary by loading random token from it\n",
    "\n",
    "    random_token_id = random.randint(0, len(id2token)-1)\n",
    "    random_token = id2token[random_token_id]\n",
    "\n",
    "    #print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "    #print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))\n",
    "\n",
    "    def _text2id(doc):\n",
    "        return [token2id[t] if t in token2id else UNK_IDX for t in doc]\n",
    "\n",
    "    def _id2text(vec):\n",
    "        return [id2token[i] for i in vec]\n",
    "\n",
    "    train_data_id = {}\n",
    "    valid_data_id = {}\n",
    "\n",
    "    train_data_id['pos'] = []\n",
    "    for d in train_data['pos']:\n",
    "        train_data_id['pos'].append(_text2id(d))\n",
    "\n",
    "    train_data_id['neg'] = []\n",
    "    for d in train_data['neg']:\n",
    "        train_data_id['neg'].append(_text2id(d))\n",
    "\n",
    "    valid_data_id['pos'] = []\n",
    "    for d in valid_data['pos']:\n",
    "        valid_data_id['pos'].append(_text2id(d))\n",
    "\n",
    "    valid_data_id['neg'] = []\n",
    "    for d in valid_data['neg']:\n",
    "        valid_data_id['neg'].append(_text2id(d))\n",
    "\n",
    "    train_data_id_merged = []\n",
    "    valid_data_id_merged = []\n",
    "\n",
    "    for d in train_data_id['pos']:\n",
    "        train_data_id_merged.append((d, 0))\n",
    "    for d in train_data_id['neg']:\n",
    "        train_data_id_merged.append((d, 1))\n",
    "\n",
    "    for d in valid_data_id['pos']:\n",
    "        valid_data_id_merged.append((d, 0))\n",
    "    for d in valid_data_id['neg']:\n",
    "        valid_data_id_merged.append((d, 1))\n",
    "\n",
    "    train_dataset = ImdbDataset(train_data_id_merged, max_inp_length=opts['max_input_length'], device='cuda')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=opts['batch_size'], collate_fn=batchify, shuffle=True)\n",
    "\n",
    "    valid_dataset = ImdbDataset(valid_data_id_merged, max_inp_length=opts['max_input_length'], device='cuda')\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=opts['batch_size'], collate_fn=batchify, shuffle=True)\n",
    "    \n",
    "    test_data = {'pos': find_ngrams(pos_test_texts_toked, opts['context_length']),\n",
    "                  'neg': find_ngrams(neg_test_texts_toked, opts['context_length'])}\n",
    "\n",
    "    test_data_id = {}\n",
    "    test_data_id['pos'] = []\n",
    "    for d in test_data['pos']:\n",
    "        test_data_id['pos'].append(_text2id(d))\n",
    "\n",
    "    test_data_id['neg'] = []\n",
    "    for d in test_data['neg']:\n",
    "        test_data_id['neg'].append(_text2id(d))\n",
    "\n",
    "    test_data_id_merged = []\n",
    "\n",
    "    for d in test_data_id['pos']:\n",
    "        test_data_id_merged.append((d, 0))\n",
    "    for d in test_data_id['neg']:\n",
    "        test_data_id_merged.append((d, 1))\n",
    "        \n",
    "    test_dataset = ImdbDataset(test_data_id_merged, max_inp_length=opts['max_input_length'], device='cuda')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=opts['batch_size'], collate_fn=batchify, shuffle=False)\n",
    "\n",
    "    model = BagOfNGrams(len(id2token), emb_dim=opts['embedding_size'], hidden_size=2048, act='Tanh', nlayers=1, reduce='mean', dropout=0.0, batch_norm=False)\n",
    "    model.cuda()\n",
    "    \n",
    "    #print(model)\n",
    "\n",
    "    learning_rate = opts['lr']\n",
    "    num_epochs = opts['num_epochs'] # number epoch to train\n",
    "\n",
    "    # Criterion and Optimizer\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(reduction='elementwise_mean')\n",
    "    if opts['optimizer'] == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.99, nesterov=True)\n",
    "    elif opts['optimizer'] == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=learning_rate)\n",
    "\n",
    "    # Function for testing the model\n",
    "    def test_model(loader, model):\n",
    "        \"\"\"\n",
    "        Help function that tests the model's performance on a dataset\n",
    "        @param: loader - data loader for the dataset to test against\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        for data, labels in loader:\n",
    "            outputs = torch.sigmoid(model(data))\n",
    "            #import ipdb; ipdb.set_trace()\n",
    "            predicted = (outputs > 0.5).long()\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "        return (100 * correct / total)\n",
    "\n",
    "    val_accs = []\n",
    "    for epoch in tqdm_notebook(range(num_epochs)):\n",
    "        for i, (data, labels) in enumerate(train_loader): \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs.view(-1), labels.float().view(-1))\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "        val_acc = test_model(loader=valid_loader, model=model)\n",
    "        val_accs.append((loss.item(),val_acc))\n",
    "            \n",
    "    return [opts, test_dataset, test_loader, val_accs, model]\n",
    "    #return [opts, val_accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c35dc46591244ffa5bf980d5d61ad7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae53a94b5bf24c2ebf82a48ec5a64052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524594328c284dc5989efb9f8a6ff86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb62ad4419804874959f5a2e6bdb80f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dc2574e67b47518359e67e0e5f80c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d558fb6b8d4f4cc1b087a6cd7434d6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e29d05160f245d6b0409bb4a0bbc273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a49f9e86d249ffbb9fda49357b5507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20592e5099c14e52b1dce79567dee407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfe9d93ebfa44f4b101e88e0650b796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for o in tqdm_notebook(prod_dicts):\n",
    "    out = do_train_val(o)\n",
    "    results.append(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(loader, model):\n",
    "        \"\"\"\n",
    "        Help function that tests the model's performance on a dataset\n",
    "        @param: loader - data loader for the dataset to test against\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        for data, labels in loader:\n",
    "            outputs = torch.sigmoid(model(data))\n",
    "            #import ipdb; ipdb.set_trace()\n",
    "            predicted = (outputs > 0.5).long()\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "        return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.616"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(loader=tl, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gridres.pkl', 'wb') as f: pickle.dump(file=f, obj=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last valacc: 80.92\n",
      "Last valacc: 55.04\n",
      "Last valacc: 80.98\n",
      "Last valacc: 60.66\n",
      "Last valacc: 82.58\n",
      "Last valacc: 60.34\n",
      "Last valacc: 73.6\n",
      "Last valacc: 69.36\n",
      "Last valacc: 75.96\n",
      "Last valacc: 51.16\n",
      "Last valacc: 58.54\n",
      "Last valacc: 50.06\n",
      "Last valacc: 75.92\n",
      "Last valacc: 52.54\n",
      "Last valacc: 69.22\n",
      "Last valacc: 62.1\n",
      "Last valacc: 50.34\n",
      "Last valacc: 49.76\n",
      "Last valacc: 55.48\n",
      "Last valacc: 50.56\n",
      "Last valacc: 69.3\n",
      "Last valacc: 50.0\n",
      "Last valacc: 63.32\n",
      "Last valacc: 52.62\n",
      "Last valacc: 50.0\n",
      "Last valacc: 51.22\n",
      "Last valacc: 50.52\n",
      "Last valacc: 50.74\n",
      "Last valacc: 54.22\n",
      "Last valacc: 50.0\n",
      "Last valacc: 62.68\n",
      "Last valacc: 52.3\n",
      "Last valacc: 84.38\n",
      "Last valacc: 58.7\n",
      "Last valacc: 84.22\n",
      "Last valacc: 60.04\n",
      "Last valacc: 83.18\n",
      "Last valacc: 58.3\n",
      "Last valacc: 79.5\n",
      "Last valacc: 69.16\n",
      "Last valacc: 84.48\n",
      "Last valacc: 51.34\n",
      "Last valacc: 87.06\n",
      "Last valacc: 51.3\n",
      "Last valacc: 82.04\n",
      "Last valacc: 52.62\n",
      "Last valacc: 84.28\n",
      "Last valacc: 60.22\n",
      "Last valacc: 78.2\n",
      "Last valacc: 50.82\n",
      "Last valacc: 67.86\n",
      "Last valacc: 50.02\n",
      "Last valacc: 78.26\n",
      "Last valacc: 52.8\n",
      "Last valacc: 79.94\n",
      "Last valacc: 54.98\n",
      "Last valacc: 53.1\n",
      "Last valacc: 49.0\n",
      "Last valacc: 69.84\n",
      "Last valacc: 50.86\n",
      "Last valacc: 71.98\n",
      "Last valacc: 49.86\n",
      "Last valacc: 73.86\n",
      "Last valacc: 50.64\n",
      "Last valacc: 50.0\n",
      "Last valacc: 51.4\n",
      "Last valacc: 46.56\n",
      "Last valacc: 55.1\n",
      "Last valacc: 83.52\n",
      "Last valacc: 72.48\n",
      "Last valacc: 60.44\n",
      "Last valacc: 79.96\n",
      "Last valacc: 50.0\n",
      "Last valacc: 52.22\n",
      "Last valacc: 50.0\n",
      "Last valacc: 49.96\n",
      "Last valacc: 76.86\n",
      "Last valacc: 65.9\n",
      "Last valacc: 63.9\n",
      "Last valacc: 59.08\n",
      "Last valacc: 51.42\n",
      "Last valacc: 51.06\n",
      "Last valacc: 50.0\n",
      "Last valacc: 50.6\n",
      "Last valacc: 48.96\n",
      "Last valacc: 52.34\n",
      "Last valacc: 50.0\n",
      "Last valacc: 54.68\n",
      "Last valacc: 48.42\n",
      "Last valacc: 50.76\n",
      "Last valacc: 50.16\n",
      "Last valacc: 50.0\n",
      "Last valacc: 50.0\n",
      "Last valacc: 51.34\n",
      "Last valacc: 50.0\n",
      "Last valacc: 50.06\n",
      "Last valacc: 82.4\n",
      "Last valacc: 63.52\n",
      "Last valacc: 50.0\n",
      "Last valacc: 69.18\n",
      "Last valacc: 81.94\n",
      "Last valacc: 80.78\n",
      "Last valacc: 82.56\n",
      "Last valacc: 76.16\n",
      "Last valacc: 87.66\n",
      "Last valacc: 50.08\n",
      "Last valacc: 84.68\n",
      "Last valacc: 52.02\n",
      "Last valacc: 84.38\n",
      "Last valacc: 59.52\n",
      "Last valacc: 83.3\n",
      "Last valacc: 63.4\n",
      "Last valacc: 50.0\n",
      "Last valacc: 50.52\n",
      "Last valacc: 50.0\n",
      "Last valacc: 52.42\n",
      "Last valacc: 81.36\n",
      "Last valacc: 54.92\n",
      "Last valacc: 82.56\n",
      "Last valacc: 52.06\n",
      "Last valacc: 50.0\n",
      "Last valacc: 50.34\n",
      "Last valacc: 49.92\n",
      "Last valacc: 51.38\n",
      "Last valacc: 77.24\n",
      "Last valacc: 50.26\n",
      "Last valacc: 50.0\n",
      "Last valacc: 52.02\n"
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    print('Last valacc: {}'.format(r[1][-1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 87.66)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([(i,r[1][-1][1]) for i,r in enumerate(results)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.1,\n",
       " 'batch_size': 512,\n",
       " 'max_voc_size': 100000,\n",
       " 'context_length': 2,\n",
       " 'max_input_length': None,\n",
       " 'embedding_size': 30,\n",
       " 'num_epochs': 20,\n",
       " 'optimizer': 'Adam'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[104]\n",
    "prod_dicts[104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849b0b04ccbf41efa2fce8f4d67f9525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1efb7abbe0c40369fd70d1bf84c0f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f964a538614287b362142f7d23a9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc6568a312e415cafd5000a214bdadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = do_train_val(prod_dicts[104])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
