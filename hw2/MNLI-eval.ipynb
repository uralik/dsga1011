{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNLI EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb5c425cac74de58c6db74942a80517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985efdc8cf374329a348c89536d72268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import csv\n",
    "import more_itertools as mit  # not built-in package\n",
    "from collections import Counter\n",
    "import torch\n",
    "try:\n",
    "    _tqdm = tqdm_notebook\n",
    "except ImportError:\n",
    "    _tqdm = tqdm\n",
    "        \n",
    "\n",
    "train_list = []\n",
    "with open('mnli_train.tsv', 'r') as trainfile:\n",
    "    train_reader = csv.reader(trainfile, delimiter='\\t')\n",
    "    \n",
    "    for row in _tqdm(train_reader):\n",
    "        train_list.append(row)\n",
    "        \n",
    "train_list = train_list[1:]\n",
    "\n",
    "valid_list = []\n",
    "with open('mnli_val.tsv', 'r') as valfile:\n",
    "    val_reader = csv.reader(valfile, delimiter='\\t')\n",
    "    \n",
    "    for row in _tqdm(val_reader):\n",
    "        valid_list.append(row)\n",
    "        \n",
    "valid_list = valid_list[1:]\n",
    "\n",
    "\n",
    "# making a vocabulary\n",
    "all_tokens = list(mit.flatten([[ll.split() for ll in l[:2]] for l in train_list] + [[ll.split() for ll in l[:2]] for l in valid_list]))\n",
    "all_tokens = list(mit.flatten(all_tokens))\n",
    "all_tokens = [t.lower() for t in all_tokens]\n",
    "\n",
    "counted_tokens = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93357a8648634b41b82a812ed20525bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0dc53efbeb44abc9bdbb9e8738d683c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "snli_train_list = []\n",
    "with open('snli_train.tsv', 'r') as trainfile:\n",
    "    train_reader = csv.reader(trainfile, delimiter='\\t')\n",
    "    \n",
    "    for row in _tqdm(train_reader):\n",
    "        snli_train_list.append(row)\n",
    "        \n",
    "snli_train_list = snli_train_list[1:]\n",
    "\n",
    "snli_valid_list = []\n",
    "with open('snli_val.tsv', 'r') as valfile:\n",
    "    val_reader = csv.reader(valfile, delimiter='\\t')\n",
    "    \n",
    "    for row in _tqdm(val_reader):\n",
    "        snli_valid_list.append(row)\n",
    "        \n",
    "snli_valid_list = snli_valid_list[1:]\n",
    "\n",
    "\n",
    "# making a vocabulary\n",
    "snli_all_tokens = list(mit.flatten([[ll.split() for ll in l[:2]] for l in snli_train_list] + [[ll.split() for ll in l[:2]] for l in snli_valid_list]))\n",
    "snli_all_tokens = list(mit.flatten(snli_all_tokens))\n",
    "snli_all_tokens = [t.lower() for t in snli_all_tokens]\n",
    "\n",
    "snli_counted_tokens = Counter(snli_all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_per_genre = {}\n",
    "for item in train_list:\n",
    "    if item[-1] not in train_list_per_genre:\n",
    "        train_list_per_genre[item[-1]] = [item[:-1]]\n",
    "    else:\n",
    "        train_list_per_genre[item[-1]].append(item[:-1])\n",
    "        \n",
    "valid_list_per_genre = {}\n",
    "for item in valid_list:\n",
    "    if item[-1] not in valid_list_per_genre:\n",
    "        valid_list_per_genre[item[-1]] = [item[:-1]]\n",
    "    else:\n",
    "        valid_list_per_genre[item[-1]].append(item[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_list_per_genre['fiction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size=None\n",
    "PAD_IDX=0\n",
    "UNK_IDX=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"and now that was in fifty one that 's forty years ago that it was already a problem so it 's now uh\",\n",
       " \"It was already a problem forty years ago but now it 's ten times worse !\",\n",
       " 'neutral',\n",
       " 'telephone']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e47ae24f94a4571a5f73b58a6b6f410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3219a79ec9c04d87ad7c89a516fd6bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=999994), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#  init fasttext weights\n",
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in _tqdm(fin):\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data\n",
    "\n",
    "words = load_vectors('./wiki-news-300d-1M.vec')\n",
    "words_dict = {}\n",
    "\n",
    "for w in _tqdm(words):\n",
    "    words_dict[w] = torch.Tensor([c for c in words[w]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from operator import itemgetter\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "vocab, count = zip(*snli_counted_tokens.most_common(max_vocab_size))\n",
    "id2token = list(vocab)\n",
    "token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "id2token = ['<pad>', '<unk>'] + id2token\n",
    "token2id['<pad>'] = PAD_IDX \n",
    "token2id['<unk>'] = UNK_IDX\n",
    "\n",
    "def _text2id(doc):\n",
    "    return [token2id[t] if t in token2id else UNK_IDX for t in doc]\n",
    "\n",
    "def _id2text(vec):\n",
    "    return [id2token[i] for i in vec]\n",
    "\n",
    "class MnliDataset(Dataset):\n",
    "    def __init__(self, data_list, device='cpu'):\n",
    "        \"\"\"\n",
    "        data_list is a list of tuples: (x,y) where x is a list of ids and y is a label\n",
    "        \"\"\"\n",
    "        labels = {\n",
    "            'neutral': 0,\n",
    "            'entailment': 1,\n",
    "            'contradiction': 2\n",
    "        }\n",
    "        self.data_tensors = []\n",
    "        for (t1, t2, label) in _tqdm(data_list):\n",
    "            _t1 = torch.LongTensor(_text2id([w.lower() for w in t1.split()])).to(device)\n",
    "            _t2 = torch.LongTensor(_text2id([w.lower() for w in t2.split()])).to(device)\n",
    "            _t1_length = len(t1.split())\n",
    "            _t2_length = len(t2.split())\n",
    "            _label = torch.LongTensor([labels[label]]).to(device)\n",
    "            self.data_tensors.append([_t1, _t1_length, _t2, _t2_length, _label])\n",
    "              \n",
    "    def __getitem__(self, key):\n",
    "        (t1, t1_len, t2, t2_len, label) = self.data_tensors[key]\n",
    "        \n",
    "        return t1, t1_len, t2, t2_len, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_tensors)\n",
    "\n",
    "def pad(tensor, length, dim=0, pad=0):\n",
    "    \"\"\"Pad tensor to a specific length.\n",
    "    :param tensor: vector to pad\n",
    "    :param length: new length\n",
    "    :param dim: (default 0) dimension to pad\n",
    "    :returns: padded tensor if the tensor is shorter than length\n",
    "    \"\"\"\n",
    "    if tensor.size(dim) < length:\n",
    "        return torch.cat(\n",
    "            [tensor, tensor.new(*tensor.size()[:dim],\n",
    "                                length - tensor.size(dim),\n",
    "                                *tensor.size()[dim + 1:]).fill_(pad)],\n",
    "            dim=dim)\n",
    "    else:\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(batch):\n",
    "    maxlen_t1 = max(batch, key = itemgetter(1))[1]\n",
    "    maxlen_t2 = max(batch, key = itemgetter(3))[3]\n",
    "    t1_batch_list = []\n",
    "    t2_batch_list = []\n",
    "    target_list = []\n",
    "    for b in batch:\n",
    "        t1_batch_list.append(pad(b[0], maxlen_t1, dim=0, pad=PAD_IDX))\n",
    "        t2_batch_list.append(pad(b[2], maxlen_t2, dim=0, pad=PAD_IDX))\n",
    "\n",
    "        target_list.append(b[4])\n",
    "    \n",
    "    lengths = torch.LongTensor([(b[1],b[3]) for b in batch]).to(b[0][0].device)\n",
    "    \n",
    "    lens_inds = torch.sort(lengths, 0, descending=True)\n",
    "    \n",
    "    t1_batch_list = torch.stack(t1_batch_list, 0).index_select(0, lens_inds[1][:,0])\n",
    "    t2_batch_list = torch.stack(t2_batch_list, 0).index_select(0, lens_inds[1][:,1])\n",
    "\n",
    "    #t1_input_batch = torch.stack(t1_batch_list, 0)\n",
    "    #t2_input_batch = torch.stack(t2_batch_list, 0)\n",
    "\n",
    "    target_batch = torch.stack(target_list, 0)\n",
    "    \n",
    "    return t1_batch_list, t2_batch_list, target_batch, lens_inds\n",
    "\n",
    "# for CNN\n",
    "def batchify_withoutsort(batch):\n",
    "    # make it for cnn\n",
    "    maxlen_t1 = max(batch, key = itemgetter(1))[1]\n",
    "    maxlen_t2 = max(batch, key = itemgetter(3))[3]\n",
    "    t1_batch_list = []\n",
    "    t2_batch_list = []\n",
    "    target_list = []\n",
    "    for b in batch:\n",
    "        t1_batch_list.append(pad(b[0], maxlen_t1, dim=0, pad=PAD_IDX))\n",
    "        t2_batch_list.append(pad(b[2], maxlen_t2, dim=0, pad=PAD_IDX))\n",
    "\n",
    "        target_list.append(b[4])\n",
    "    \n",
    "#     lengths = torch.LongTensor([(b[1],b[3]) for b in batch]).to(b[0][0].device)\n",
    "    \n",
    "#     lens_inds = torch.sort(lengths, 0, descending=True)\n",
    "    \n",
    "#     t1_batch_list = torch.stack(t1_batch_list, 0).index_select(0, lens_inds[1][:,0])\n",
    "#     t2_batch_list = torch.stack(t2_batch_list, 0).index_select(0, lens_inds[1][:,1])\n",
    "\n",
    "    t1_input_batch = torch.stack(t1_batch_list, 0)\n",
    "    t2_input_batch = torch.stack(t2_batch_list, 0)\n",
    "\n",
    "    target_batch = torch.stack(target_list, 0)\n",
    "    \n",
    "    return t1_input_batch, t2_input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5b55fd6ad04fe9b6b264cd675241f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4270), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724c545d132d4f8cbd9891acababec86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3836), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe33691e0b384b45aece6501787371fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4026), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c7133a5a6242e1a3980744e9597498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3883), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070260bbf66041d9b9243ee8afbbb693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3985), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0247064c7945dbb14fae94a4fd5544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=995), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c2afdd46684d638e571b36f0501e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1005), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98902bf0ea704993b332c572b2ed472e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1002), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a8a78c213b4a48819b750951cccf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1016), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfd19c486dc43a58d140fc2108c6434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=982), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mnli_train = {}\n",
    "mnli_valid = {}\n",
    "\n",
    "for genre in train_list_per_genre.keys():\n",
    "    mnli_train[genre] = {'dataset': MnliDataset(train_list_per_genre[genre], device='cuda')}\n",
    "    mnli_train[genre]['rnn_loader'] = DataLoader(mnli_train[genre]['dataset'], batch_size=512, collate_fn=batchify, shuffle=True)\n",
    "    mnli_train[genre]['cnn_loader'] = DataLoader(mnli_train[genre]['dataset'], batch_size=512, collate_fn=batchify_withoutsort, shuffle=True)\n",
    "    \n",
    "for genre in valid_list_per_genre.keys():\n",
    "    mnli_valid[genre] = {'dataset': MnliDataset(valid_list_per_genre[genre], device='cuda')}\n",
    "    mnli_valid[genre]['rnn_loader'] = DataLoader(mnli_valid[genre]['dataset'], batch_size=512, collate_fn=batchify, shuffle=False)\n",
    "    mnli_valid[genre]['cnn_loader'] = DataLoader(mnli_valid[genre]['dataset'], batch_size=512, collate_fn=batchify_withoutsort, shuffle=False)\n",
    "\n",
    "\n",
    "# snli_train_dataset = SnliDataset(train_list, device='cuda')\n",
    "# train_loader = DataLoader(snli_train_dataset, batch_size=512, collate_fn=batchify, shuffle=True)\n",
    "\n",
    "# snli_valid_dataset = SnliDataset(valid_list, device='cuda')\n",
    "# valid_loader = DataLoader(snli_valid_dataset, batch_size=512, collate_fn=batchify, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([19784, 20900,   220,  6135,   579,     1], device='cuda:0'),\n",
       " 6,\n",
       " tensor([    4, 11610,    11, 20900,     6,   165,   579,     1], device='cuda:0'),\n",
       " 8,\n",
       " tensor([1], device='cuda:0'))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_valid['telephone']['dataset'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  142,  4529,  1280,    16,   744,   142,  1023,  1280,     3,   296,\n",
       "             1, 18806,    92,     3], device='cuda:0'),\n",
       " 14,\n",
       " tensor([ 142, 2182, 4529, 1280,   16,  853,  142, 3768,   54,  186, 1280,    1,\n",
       "            3], device='cuda:0'),\n",
       " 13,\n",
       " tensor([2], device='cuda:0'))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_valid['fiction']['dataset'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "#  copy fasttext vectors into embeddings weights given the vocabulary\n",
    "\n",
    "class RNNEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, id2token, embedding_size=300, num_layers=1, classifier_hidden=512, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.embedding = self._copy_embedding_weights(words, id2token, embedding_size)\n",
    "        self.encoder = nn.GRU(num_layers=num_layers, hidden_size=hidden_size, bias=True, input_size=embedding_size, batch_first=True,\n",
    "                             bidirectional=True)\n",
    "        \n",
    "        self.classifier = nn.ModuleList([nn.Linear(4*hidden_size, classifier_hidden), nn.Tanh(), nn.Dropout(p=dropout), nn.Linear(classifier_hidden, 3)])\n",
    "        \n",
    "\n",
    "    def _copy_embedding_weights(self, words, id2token, embedding_size=300):\n",
    "        embedding = nn.Embedding(embedding_dim=embedding_size, num_embeddings=len(id2token), padding_idx=0)\n",
    "        cnt = 0\n",
    "        for i,w in enumerate(id2token):\n",
    "            if w in words:\n",
    "                embedding.weight.data[i] = words_dict[w]\n",
    "                cnt +=1 \n",
    "        print('{} words copied into nn.Embedding'.format(cnt))\n",
    "        return embedding\n",
    "        \n",
    "    def forward(self, t1, t2, lens_inds):\n",
    "        t1_embedded = self.embedding(t1)\n",
    "        t2_embedded = self.embedding(t2)\n",
    "        t1_packed = pack_padded_sequence(t1_embedded, lens_inds[0][:,0], batch_first=True)\n",
    "        t2_packed = pack_padded_sequence(t2_embedded, lens_inds[0][:,1], batch_first=True)\n",
    "        \n",
    "        t1_grued = self.encoder(t1_packed)\n",
    "        t2_grued = self.encoder(t2_packed)\n",
    "        t1_out = torch.cat(torch.unbind(t1_grued[1], 0), dim=-1)\n",
    "        t2_out = torch.cat(torch.unbind(t2_grued[1], 0), dim=-1)\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        # need to reorder back firstly\n",
    "        #assert len(sorted_indices[0]) == len(sorted_indices[1])\n",
    "        t1_out = t1_out.index_select(dim=0, index=torch.sort(lens_inds[1][:,0])[1])\n",
    "        t2_out = t2_out.index_select(dim=0, index=torch.sort(lens_inds[1][:,1])[1])\n",
    "        \n",
    "        classifier_input = torch.cat([t1_out, t2_out], dim=-1)\n",
    "\n",
    "        x = classifier_input\n",
    "        for l in self.classifier:\n",
    "            x = l(x)\n",
    "        \n",
    "        class_out = x\n",
    "        \n",
    "        return class_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, id2token, embedding_size=300, num_layers=1, classifier_hidden=512, kernel_size=3, pool_kernel_size=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = self._copy_embedding_weights(words, id2token, embedding_size)\n",
    "        self.embedding.weight.requires_grad=False\n",
    "        self.encoder = nn.ModuleList([nn.Conv1d(in_channels=embedding_size, out_channels=hidden_size, kernel_size=kernel_size, stride=1), nn.MaxPool1d(stride=1, kernel_size=pool_kernel_size) , nn.ReLU(), nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size, kernel_size=kernel_size, stride=1), nn.Dropout(p=dropout)])\n",
    "        \n",
    "        self.classifier = nn.ModuleList([nn.Linear(2*hidden_size, classifier_hidden), nn.Tanh(), nn.Dropout(p=dropout), nn.Linear(classifier_hidden, 3)])\n",
    "        \n",
    "\n",
    "    def _copy_embedding_weights(self, words, id2token, embedding_size=300):\n",
    "        embedding = nn.Embedding(embedding_dim=embedding_size, num_embeddings=len(id2token), padding_idx=0)\n",
    "        cnt = 0\n",
    "        for i,w in enumerate(id2token):\n",
    "            if w in words:\n",
    "                embedding.weight.data[i] = words_dict[w]\n",
    "                cnt +=1 \n",
    "        print('{} words copied into nn.Embedding'.format(cnt))\n",
    "        return embedding\n",
    "    \n",
    "    def _encode(self, x):\n",
    "        for l in self.encoder:\n",
    "            x = l(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def _classify(self, x):\n",
    "        for l in self.classifier:\n",
    "            x = l(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "    def forward(self, t1, t2):\n",
    "        embedded = []\n",
    "        embedded.append(self.embedding(t1))\n",
    "        embedded.append(self.embedding(t2))\n",
    "           \n",
    "        cnn_out = []\n",
    "        \n",
    "        for i in range(2):\n",
    "            _out = self._encode(embedded[i].permute(0,2,1))\n",
    "            cnn_out.append(F.max_pool1d(_out , kernel_size=_out.size(-1)).squeeze(-1))\n",
    "            #import ipdb; ipdb.set_trace()\n",
    "            \n",
    "        #import ipdb; ipdb.set_trace()\n",
    "\n",
    "        classifier_input = torch.cat(cnn_out, dim=1)\n",
    "        classifier_out = self._classify(classifier_input)\n",
    "        \n",
    "        \n",
    "        return classifier_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading CNN grids pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cnn_grid.pkl', 'rb') as f:\n",
    "    grids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_model = 0\n",
    "best_grid = None\n",
    "for model in grids:\n",
    "    if model[-1]['valid_acc'] > best_val_model:\n",
    "        best_grid = model\n",
    "        best_val_model = model[-1]['valid_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.669"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNEncoder(\n",
       "  (embedding): Embedding(21115, 300, padding_idx=0)\n",
       "  (encoder): ModuleList(\n",
       "    (0): Conv1d(300, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (4): Dropout(p=0.0)\n",
       "  )\n",
       "  (classifier): ModuleList(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.0)\n",
       "    (3): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnnmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19027 words copied into nn.Embedding\n"
     ]
    }
   ],
   "source": [
    "best_conf = best_grid[-1]['configuration']\n",
    "cnnmodel = CNNEncoder(best_conf['cnn_hidden'], id2token, classifier_hidden=512, dropout=best_conf['dropout'], embedding_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnmodel.load_state_dict(best_grid[-1]['model_dict'])\n",
    "cnnmodel = cnnmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _do_valid_rnn(rnnencoder, valid_loader, metrics, mode='valid'):\n",
    "    rnnencoder.eval()\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    for i,(t1,t2,target, lens) in enumerate(valid_loader):\n",
    "        output = rnnencoder(t1,t2, lens)\n",
    "        predicted = torch.argmax(output, 1)\n",
    "        correct += (target.view(-1) == predicted.view(-1)).sum().item()\n",
    "        processed += predicted.size(0)\n",
    "        if i == 25 and mode == 'train':\n",
    "            break\n",
    "    print('Acc {}: {}'.format(mode, correct/processed))\n",
    "    \n",
    "def _do_valid_cnn(cnnencoder, valid_loader, metrics, mode='valid'):\n",
    "    cnnencoder.eval()\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    for i,(t1,t2,target) in enumerate(valid_loader):\n",
    "        output = cnnencoder(t1,t2)\n",
    "        predicted = torch.argmax(output, 1)\n",
    "        correct += (target.view(-1) == predicted.view(-1)).sum().item()\n",
    "        processed += predicted.size(0)\n",
    "        if i == 25 and mode == 'train':\n",
    "            break\n",
    "    print('Acc {}: {}'.format(mode, correct/processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc valid: 0.3574338085539715\n",
      "Acc valid: 0.3574338085539715\n",
      "Acc valid: 0.3574338085539715\n",
      "Acc valid: 0.3574338085539715\n",
      "Acc valid: 0.3574338085539715\n"
     ]
    }
   ],
   "source": [
    "for gengre in valid_list_per_genre.keys():\n",
    "    _do_valid_cnn(cnnmodel, mnli_valid[genre]['cnn_loader'], metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-48-f92caf61d699>\u001b[0m(19)\u001b[0;36m_do_valid_cnn\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     18 \u001b[0;31m    \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 19 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnnencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  valid_loader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f3ed7e82c88>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  for t in valid_loader: print(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[    9,  1428,   205,  ...,  4816,   142,  1089],\n",
      "        [13373,   142,  2471,  ...,     0,     0,     0],\n",
      "        [    1,     4,     4,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [18872,  3499,     0,  ...,     0,     0,     0],\n",
      "        [11664,     1,     0,  ...,     0,     0,     0],\n",
      "        [  626,   317,     0,  ...,     0,     0,     0]], device='cuda:0'), tensor([[  193,    35,  1474,  ..., 10620,   862,     3],\n",
      "        [   92,  1738,   469,  ...,     0,     0,     0],\n",
      "        [ 1428,  2471,  1082,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 7905,  1280,  2493,  ...,     0,     0,     0],\n",
      "        [10008,  2605,     0,  ...,     0,     0,     0],\n",
      "        [    1,     0,     0,  ...,     0,     0,     0]], device='cuda:0'), tensor([[2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1]], device='cuda:0'), (tensor([[205,  39],\n",
      "        [202,  35],\n",
      "        [163,  30],\n",
      "        ...,\n",
      "        [  2,   3],\n",
      "        [  2,   2],\n",
      "        [  2,   1]], device='cuda:0'), tensor([[443, 352],\n",
      "        [237,  85],\n",
      "        [238, 154],\n",
      "        ...,\n",
      "        [477, 464],\n",
      "        [167, 247],\n",
      "        [192, 167]], device='cuda:0')))\n",
      "(tensor([[13373,   142,  2471,  ...,     2,    61,  5224],\n",
      "        [    1,     4,     4,  ...,     0,     0,     0],\n",
      "        [ 1428,  1550,    97,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2916,     6,   328,  ...,     0,     0,     0],\n",
      "        [  626,   317,     0,  ...,     0,     0,     0],\n",
      "        [11664,     1,     0,  ...,     0,     0,     0]], device='cuda:0'), tensor([[   1,  142, 2234,  ..., 4200,  231,    3],\n",
      "        [  48,  783, 2456,  ...,    4,  378,    3],\n",
      "        [  97,   87, 8901,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 283,   16,  283,  ...,    0,    0,    0],\n",
      "        [  11,  823,    0,  ...,    0,    0,    0],\n",
      "        [   1,    0,    0,  ...,    0,    0,    0]], device='cuda:0'), tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]], device='cuda:0'), (tensor([[202,  32],\n",
      "        [163,  32],\n",
      "        [133,  29],\n",
      "        [133,  28],\n",
      "        [128,  27],\n",
      "        [124,  25],\n",
      "        [109,  25],\n",
      "        [ 91,  24],\n",
      "        [ 91,  24],\n",
      "        [ 88,  24],\n",
      "        [ 86,  24],\n",
      "        [ 77,  23],\n",
      "        [ 74,  22],\n",
      "        [ 72,  21],\n",
      "        [ 69,  21],\n",
      "        [ 66,  21],\n",
      "        [ 66,  21],\n",
      "        [ 66,  21],\n",
      "        [ 65,  21],\n",
      "        [ 65,  20],\n",
      "        [ 65,  20],\n",
      "        [ 62,  20],\n",
      "        [ 59,  20],\n",
      "        [ 59,  19],\n",
      "        [ 58,  19],\n",
      "        [ 58,  19],\n",
      "        [ 57,  19],\n",
      "        [ 57,  19],\n",
      "        [ 56,  19],\n",
      "        [ 56,  19],\n",
      "        [ 56,  18],\n",
      "        [ 55,  18],\n",
      "        [ 55,  18],\n",
      "        [ 55,  18],\n",
      "        [ 55,  18],\n",
      "        [ 54,  18],\n",
      "        [ 54,  18],\n",
      "        [ 54,  18],\n",
      "        [ 54,  18],\n",
      "        [ 53,  18],\n",
      "        [ 52,  18],\n",
      "        [ 52,  18],\n",
      "        [ 52,  17],\n",
      "        [ 51,  17],\n",
      "        [ 51,  17],\n",
      "        [ 50,  17],\n",
      "        [ 50,  17],\n",
      "        [ 50,  17],\n",
      "        [ 49,  17],\n",
      "        [ 49,  17],\n",
      "        [ 48,  17],\n",
      "        [ 48,  17],\n",
      "        [ 47,  17],\n",
      "        [ 47,  17],\n",
      "        [ 47,  17],\n",
      "        [ 46,  17],\n",
      "        [ 46,  16],\n",
      "        [ 46,  16],\n",
      "        [ 46,  16],\n",
      "        [ 45,  16],\n",
      "        [ 45,  16],\n",
      "        [ 45,  16],\n",
      "        [ 45,  16],\n",
      "        [ 44,  16],\n",
      "        [ 44,  16],\n",
      "        [ 44,  16],\n",
      "        [ 44,  16],\n",
      "        [ 44,  16],\n",
      "        [ 44,  16],\n",
      "        [ 44,  16],\n",
      "        [ 43,  16],\n",
      "        [ 43,  16],\n",
      "        [ 43,  16],\n",
      "        [ 42,  15],\n",
      "        [ 42,  15],\n",
      "        [ 42,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 41,  15],\n",
      "        [ 40,  15],\n",
      "        [ 40,  15],\n",
      "        [ 40,  15],\n",
      "        [ 39,  15],\n",
      "        [ 39,  15],\n",
      "        [ 39,  15],\n",
      "        [ 39,  15],\n",
      "        [ 38,  15],\n",
      "        [ 37,  14],\n",
      "        [ 37,  14],\n",
      "        [ 37,  14],\n",
      "        [ 37,  14],\n",
      "        [ 37,  14],\n",
      "        [ 37,  14],\n",
      "        [ 36,  14],\n",
      "        [ 36,  14],\n",
      "        [ 36,  14],\n",
      "        [ 36,  14],\n",
      "        [ 36,  14],\n",
      "        [ 36,  14],\n",
      "        [ 36,  14],\n",
      "        [ 36,  14],\n",
      "        [ 35,  14],\n",
      "        [ 35,  14],\n",
      "        [ 35,  14],\n",
      "        [ 35,  14],\n",
      "        [ 35,  14],\n",
      "        [ 34,  14],\n",
      "        [ 34,  14],\n",
      "        [ 34,  14],\n",
      "        [ 34,  14],\n",
      "        [ 34,  14],\n",
      "        [ 34,  14],\n",
      "        [ 33,  14],\n",
      "        [ 33,  14],\n",
      "        [ 33,  13],\n",
      "        [ 33,  13],\n",
      "        [ 32,  13],\n",
      "        [ 32,  13],\n",
      "        [ 32,  13],\n",
      "        [ 31,  13],\n",
      "        [ 31,  13],\n",
      "        [ 31,  13],\n",
      "        [ 31,  13],\n",
      "        [ 30,  13],\n",
      "        [ 30,  13],\n",
      "        [ 30,  13],\n",
      "        [ 30,  13],\n",
      "        [ 30,  13],\n",
      "        [ 30,  13],\n",
      "        [ 29,  13],\n",
      "        [ 29,  13],\n",
      "        [ 29,  13],\n",
      "        [ 29,  13],\n",
      "        [ 29,  13],\n",
      "        [ 29,  13],\n",
      "        [ 29,  13],\n",
      "        [ 29,  13],\n",
      "        [ 29,  13],\n",
      "        [ 28,  13],\n",
      "        [ 28,  13],\n",
      "        [ 28,  13],\n",
      "        [ 28,  13],\n",
      "        [ 28,  13],\n",
      "        [ 28,  13],\n",
      "        [ 28,  13],\n",
      "        [ 28,  13],\n",
      "        [ 28,  13],\n",
      "        [ 28,  13],\n",
      "        [ 28,  13],\n",
      "        [ 27,  13],\n",
      "        [ 27,  12],\n",
      "        [ 27,  12],\n",
      "        [ 27,  12],\n",
      "        [ 27,  12],\n",
      "        [ 27,  12],\n",
      "        [ 27,  12],\n",
      "        [ 27,  12],\n",
      "        [ 26,  12],\n",
      "        [ 26,  12],\n",
      "        [ 26,  12],\n",
      "        [ 26,  12],\n",
      "        [ 26,  12],\n",
      "        [ 25,  12],\n",
      "        [ 25,  12],\n",
      "        [ 25,  12],\n",
      "        [ 25,  12],\n",
      "        [ 25,  12],\n",
      "        [ 25,  12],\n",
      "        [ 25,  12],\n",
      "        [ 25,  12],\n",
      "        [ 25,  12],\n",
      "        [ 24,  12],\n",
      "        [ 24,  12],\n",
      "        [ 24,  12],\n",
      "        [ 24,  12],\n",
      "        [ 24,  12],\n",
      "        [ 24,  12],\n",
      "        [ 23,  12],\n",
      "        [ 23,  12],\n",
      "        [ 23,  12],\n",
      "        [ 23,  12],\n",
      "        [ 23,  12],\n",
      "        [ 23,  12],\n",
      "        [ 23,  12],\n",
      "        [ 23,  12],\n",
      "        [ 22,  12],\n",
      "        [ 22,  11],\n",
      "        [ 22,  11],\n",
      "        [ 22,  11],\n",
      "        [ 22,  11],\n",
      "        [ 22,  11],\n",
      "        [ 22,  11],\n",
      "        [ 22,  11],\n",
      "        [ 22,  11],\n",
      "        [ 22,  11],\n",
      "        [ 21,  11],\n",
      "        [ 21,  11],\n",
      "        [ 21,  11],\n",
      "        [ 21,  11],\n",
      "        [ 21,  11],\n",
      "        [ 21,  11],\n",
      "        [ 21,  11],\n",
      "        [ 20,  11],\n",
      "        [ 20,  11],\n",
      "        [ 20,  11],\n",
      "        [ 20,  11],\n",
      "        [ 20,  11],\n",
      "        [ 20,  11],\n",
      "        [ 20,  11],\n",
      "        [ 20,  11],\n",
      "        [ 20,  11],\n",
      "        [ 20,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  11],\n",
      "        [ 19,  10],\n",
      "        [ 19,  10],\n",
      "        [ 18,  10],\n",
      "        [ 18,  10],\n",
      "        [ 18,  10],\n",
      "        [ 18,  10],\n",
      "        [ 18,  10],\n",
      "        [ 18,  10],\n",
      "        [ 18,  10],\n",
      "        [ 18,  10],\n",
      "        [ 18,  10],\n",
      "        [ 17,  10],\n",
      "        [ 17,  10],\n",
      "        [ 17,  10],\n",
      "        [ 17,  10],\n",
      "        [ 17,  10],\n",
      "        [ 17,  10],\n",
      "        [ 17,  10],\n",
      "        [ 17,  10],\n",
      "        [ 17,  10],\n",
      "        [ 17,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 16,  10],\n",
      "        [ 15,  10],\n",
      "        [ 15,  10],\n",
      "        [ 15,  10],\n",
      "        [ 15,  10],\n",
      "        [ 15,  10],\n",
      "        [ 15,  10],\n",
      "        [ 14,  10],\n",
      "        [ 14,  10],\n",
      "        [ 14,  10],\n",
      "        [ 14,  10],\n",
      "        [ 14,  10],\n",
      "        [ 14,  10],\n",
      "        [ 14,   9],\n",
      "        [ 14,   9],\n",
      "        [ 14,   9],\n",
      "        [ 14,   9],\n",
      "        [ 14,   9],\n",
      "        [ 14,   9],\n",
      "        [ 14,   9],\n",
      "        [ 14,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 13,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   9],\n",
      "        [ 12,   8],\n",
      "        [ 12,   8],\n",
      "        [ 12,   8],\n",
      "        [ 12,   8],\n",
      "        [ 12,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 11,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [ 10,   8],\n",
      "        [  9,   8],\n",
      "        [  9,   8],\n",
      "        [  9,   8],\n",
      "        [  9,   8],\n",
      "        [  9,   8],\n",
      "        [  9,   8],\n",
      "        [  9,   8],\n",
      "        [  9,   8],\n",
      "        [  9,   8],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  9,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  8,   7],\n",
      "        [  7,   7],\n",
      "        [  7,   7],\n",
      "        [  7,   7],\n",
      "        [  7,   7],\n",
      "        [  7,   7],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  7,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  6,   6],\n",
      "        [  5,   6],\n",
      "        [  5,   6],\n",
      "        [  5,   6],\n",
      "        [  5,   6],\n",
      "        [  5,   5],\n",
      "        [  5,   5],\n",
      "        [  5,   5],\n",
      "        [  5,   5],\n",
      "        [  5,   5],\n",
      "        [  5,   5],\n",
      "        [  5,   5],\n",
      "        [  5,   5],\n",
      "        [  5,   5],\n",
      "        [  5,   5],\n",
      "        [  5,   5],\n",
      "        [  5,   5],\n",
      "        [  4,   5],\n",
      "        [  4,   5],\n",
      "        [  4,   5],\n",
      "        [  4,   5],\n",
      "        [  4,   5],\n",
      "        [  4,   4],\n",
      "        [  4,   4],\n",
      "        [  4,   4],\n",
      "        [  4,   4],\n",
      "        [  4,   4],\n",
      "        [  4,   4],\n",
      "        [  4,   4],\n",
      "        [  3,   4],\n",
      "        [  3,   4],\n",
      "        [  3,   4],\n",
      "        [  3,   4],\n",
      "        [  3,   4],\n",
      "        [  3,   4],\n",
      "        [  3,   4],\n",
      "        [  3,   4],\n",
      "        [  3,   3],\n",
      "        [  3,   3],\n",
      "        [  3,   3],\n",
      "        [  3,   3],\n",
      "        [  2,   2],\n",
      "        [  2,   1]], device='cuda:0'), tensor([[337,  12],\n",
      "        [272, 258],\n",
      "        [364, 330],\n",
      "        [486, 301],\n",
      "        [117,  74],\n",
      "        [209, 448],\n",
      "        [103, 419],\n",
      "        [199, 299],\n",
      "        [104, 126],\n",
      "        [132, 399],\n",
      "        [433,  81],\n",
      "        [448,  28],\n",
      "        [ 37, 204],\n",
      "        [367, 410],\n",
      "        [161, 337],\n",
      "        [405, 394],\n",
      "        [143, 205],\n",
      "        [ 21,  56],\n",
      "        [365, 220],\n",
      "        [485, 365],\n",
      "        [202, 415],\n",
      "        [261, 366],\n",
      "        [226, 409],\n",
      "        [204,  67],\n",
      "        [439, 461],\n",
      "        [ 67, 434],\n",
      "        [159, 124],\n",
      "        [327, 196],\n",
      "        [297, 336],\n",
      "        [266, 348],\n",
      "        [186, 423],\n",
      "        [489, 406],\n",
      "        [358, 147],\n",
      "        [347,  22],\n",
      "        [278, 324],\n",
      "        [258, 308],\n",
      "        [ 60, 229],\n",
      "        [ 31, 192],\n",
      "        [ 95, 127],\n",
      "        [228,  61],\n",
      "        [465, 209],\n",
      "        [ 74, 186],\n",
      "        [301, 117],\n",
      "        [126, 143],\n",
      "        [128,  24],\n",
      "        [322, 103],\n",
      "        [296,  47],\n",
      "        [328,  13],\n",
      "        [460, 318],\n",
      "        [ 56, 279],\n",
      "        [ 12, 214],\n",
      "        [ 18, 397],\n",
      "        [ 28, 449],\n",
      "        [318, 281],\n",
      "        [345, 262],\n",
      "        [ 15, 350],\n",
      "        [136, 468],\n",
      "        [184, 463],\n",
      "        [370, 402],\n",
      "        [163, 309],\n",
      "        [389, 376],\n",
      "        [293, 328],\n",
      "        [267, 359],\n",
      "        [372, 395],\n",
      "        [ 40,   0],\n",
      "        [422,  21],\n",
      "        [ 51,  45],\n",
      "        [ 10, 215],\n",
      "        [280, 177],\n",
      "        [233, 241],\n",
      "        [ 47, 136],\n",
      "        [190, 100],\n",
      "        [ 79, 148],\n",
      "        [330, 137],\n",
      "        [213, 488],\n",
      "        [147, 216],\n",
      "        [384, 162],\n",
      "        [346, 188],\n",
      "        [335, 252],\n",
      "        [424, 471],\n",
      "        [ 32, 422],\n",
      "        [ 25, 424],\n",
      "        [ 48, 451],\n",
      "        [248, 338],\n",
      "        [137, 283],\n",
      "        [172, 300],\n",
      "        [406, 296],\n",
      "        [477,  66],\n",
      "        [ 68,  48],\n",
      "        [ 65,  38],\n",
      "        [114,  55],\n",
      "        [349,  17],\n",
      "        [391,  79],\n",
      "        [127,  71],\n",
      "        [177,  92],\n",
      "        [434, 114],\n",
      "        [390, 370],\n",
      "        [289, 489],\n",
      "        [441, 486],\n",
      "        [234, 202],\n",
      "        [383, 412],\n",
      "        [423, 225],\n",
      "        [368, 450],\n",
      "        [ 43, 477],\n",
      "        [156, 467],\n",
      "        [214, 320],\n",
      "        [399, 317],\n",
      "        [408, 260],\n",
      "        [339, 417],\n",
      "        [183, 469],\n",
      "        [ 61, 438],\n",
      "        [476, 447],\n",
      "        [468, 233],\n",
      "        [336, 250],\n",
      "        [ 26,  59],\n",
      "        [  6,  73],\n",
      "        [320,  32],\n",
      "        [179, 149],\n",
      "        [165, 183],\n",
      "        [  7, 152],\n",
      "        [396, 208],\n",
      "        [427, 478],\n",
      "        [ 35, 184],\n",
      "        [341, 170],\n",
      "        [ 39, 392],\n",
      "        [ 99,   8],\n",
      "        [316, 396],\n",
      "        [237, 460],\n",
      "        [189, 178],\n",
      "        [308, 180],\n",
      "        [ 71, 244],\n",
      "        [ 38, 248],\n",
      "        [356, 146],\n",
      "        [410, 156],\n",
      "        [313, 173],\n",
      "        [400, 151],\n",
      "        [447, 145],\n",
      "        [119, 128],\n",
      "        [150, 131],\n",
      "        [ 44,  51],\n",
      "        [241,  98],\n",
      "        [451,  68],\n",
      "        [338,  95],\n",
      "        [359, 245],\n",
      "        [122, 291],\n",
      "        [ 45, 313],\n",
      "        [352, 270],\n",
      "        [151, 305],\n",
      "        [ 76, 303],\n",
      "        [ 81, 297],\n",
      "        [ 98, 269],\n",
      "        [ 77, 408],\n",
      "        [146, 454],\n",
      "        [173, 433],\n",
      "        [ 59, 400],\n",
      "        [271, 439],\n",
      "        [398, 331],\n",
      "        [473, 341],\n",
      "        [376,  19],\n",
      "        [402,  80],\n",
      "        [ 90, 340],\n",
      "        [118, 347],\n",
      "        [307, 219],\n",
      "        [ 42, 239],\n",
      "        [192, 227],\n",
      "        [196, 211],\n",
      "        [215, 138],\n",
      "        [239, 130],\n",
      "        [324, 268],\n",
      "        [415, 267],\n",
      "        [100, 276],\n",
      "        [299, 322],\n",
      "        [363, 346],\n",
      "        [ 93, 358],\n",
      "        [135, 465],\n",
      "        [ 30, 343],\n",
      "        [386, 104],\n",
      "        [292, 228],\n",
      "        [291, 235],\n",
      "        [348,  41],\n",
      "        [ 84,   1],\n",
      "        [395,  15],\n",
      "        [ 80,  39],\n",
      "        [478,  18],\n",
      "        [ 57, 166],\n",
      "        [174, 172],\n",
      "        [ 64,  60],\n",
      "        [105, 157],\n",
      "        [350, 132],\n",
      "        [124, 159],\n",
      "        [157, 294],\n",
      "        [116, 293],\n",
      "        [268, 492],\n",
      "        [409, 485],\n",
      "        [438, 372],\n",
      "        [152, 379],\n",
      "        [220, 436],\n",
      "        [211, 398],\n",
      "        [488,   6],\n",
      "        [260, 185],\n",
      "        [210,  93],\n",
      "        [178,  84],\n",
      "        [ 89,  31],\n",
      "        [290,   7],\n",
      "        [314, 107],\n",
      "        [205, 111],\n",
      "        [492, 190],\n",
      "        [469,  35],\n",
      "        [259, 403],\n",
      "        [309, 437],\n",
      "        [149, 314],\n",
      "        [323, 278],\n",
      "        [  4, 272],\n",
      "        [235, 304],\n",
      "        [276, 315],\n",
      "        [ 55, 266],\n",
      "        [333, 375],\n",
      "        [371, 356],\n",
      "        [123,  65],\n",
      "        [154,  78],\n",
      "        [145,  44],\n",
      "        [ 22,  36],\n",
      "        [459, 284],\n",
      "        [436, 259],\n",
      "        [285, 175],\n",
      "        [419, 165],\n",
      "        [393, 217],\n",
      "        [482, 198],\n",
      "        [374, 255],\n",
      "        [321, 129],\n",
      "        [208, 118],\n",
      "        [166, 120],\n",
      "        [223, 154],\n",
      "        [231, 261],\n",
      "        [253, 334],\n",
      "        [252, 344],\n",
      "        [ 66, 339],\n",
      "        [284, 345],\n",
      "        [264,  49],\n",
      "        [269,  54],\n",
      "        [130, 335],\n",
      "        [ 52, 455],\n",
      "        [109, 414],\n",
      "        [216, 391],\n",
      "        [354, 316],\n",
      "        [366, 371],\n",
      "        [343, 368],\n",
      "        [106, 290],\n",
      "        [270, 420],\n",
      "        [217, 418],\n",
      "        [458, 393],\n",
      "        [454, 441],\n",
      "        [310, 431],\n",
      "        [414, 271],\n",
      "        [305, 306],\n",
      "        [471, 287],\n",
      "        [ 78, 113],\n",
      "        [167, 109],\n",
      "        [463, 197],\n",
      "        [  2, 193],\n",
      "        [188, 223],\n",
      "        [ 29, 210],\n",
      "        [  9, 201],\n",
      "        [467, 155],\n",
      "        [450, 158],\n",
      "        [444, 161],\n",
      "        [373, 189],\n",
      "        [262, 164],\n",
      "        [295, 199],\n",
      "        [332, 226],\n",
      "        [317, 237],\n",
      "        [369, 253],\n",
      "        [ 53, 150],\n",
      "        [455, 116],\n",
      "        [219,  52],\n",
      "        [164, 119],\n",
      "        [229,  43],\n",
      "        [ 17,  42],\n",
      "        [232,  30],\n",
      "        [224,  16],\n",
      "        [  8,  11],\n",
      "        [287,  14],\n",
      "        [381,   4],\n",
      "        [ 83,  58],\n",
      "        [319,  64],\n",
      "        [466,  96],\n",
      "        [449, 105],\n",
      "        [331,  94],\n",
      "        [ 75, 364],\n",
      "        [ 24, 312],\n",
      "        [ 92, 236],\n",
      "        [125,  57],\n",
      "        [110,  20],\n",
      "        [484,  29],\n",
      "        [412,  33],\n",
      "        [ 94,  40],\n",
      "        [138, 473],\n",
      "        [227, 472],\n",
      "        [429, 401],\n",
      "        [ 54, 333],\n",
      "        [379, 326],\n",
      "        [ 41,  75],\n",
      "        [ 20,  83],\n",
      "        [401, 490],\n",
      "        [201, 369],\n",
      "        [169, 323],\n",
      "        [180, 288],\n",
      "        [212, 444],\n",
      "        [153, 459],\n",
      "        [279, 458],\n",
      "        [315, 466],\n",
      "        [283, 476],\n",
      "        [428, 411],\n",
      "        [392, 435],\n",
      "        [394, 421],\n",
      "        [417, 384],\n",
      "        [397, 413],\n",
      "        [416, 377],\n",
      "        [437, 349],\n",
      "        [255, 329],\n",
      "        [ 46,  99],\n",
      "        [ 73, 144],\n",
      "        [218, 213],\n",
      "        [ 13, 169],\n",
      "        [ 69, 179],\n",
      "        [108, 133],\n",
      "        [195, 174],\n",
      "        [222, 247],\n",
      "        [294, 122],\n",
      "        [197, 108],\n",
      "        [225,  97],\n",
      "        [430,   2],\n",
      "        [418,  10],\n",
      "        [435,  23],\n",
      "        [472,  25],\n",
      "        [464,  89],\n",
      "        [273, 231],\n",
      "        [304, 222],\n",
      "        [207, 218],\n",
      "        [306, 243],\n",
      "        [281,  87],\n",
      "        [353,  69],\n",
      "        [334,  90],\n",
      "        [351,  26],\n",
      "        [  0, 249],\n",
      "        [206, 234],\n",
      "        [245, 135],\n",
      "        [ 27, 163],\n",
      "        [250, 167],\n",
      "        [230, 206],\n",
      "        [ 23, 207],\n",
      "        [198,   9],\n",
      "        [442, 390],\n",
      "        [490, 416],\n",
      "        [474, 456],\n",
      "        [385, 482],\n",
      "        [432, 405],\n",
      "        [440, 386],\n",
      "        [158, 457],\n",
      "        [148, 101],\n",
      "        [357, 110],\n",
      "        [382,  76],\n",
      "        [102, 115],\n",
      "        [ 50, 121],\n",
      "        [175, 142],\n",
      "        [162, 181],\n",
      "        [247, 191],\n",
      "        [246, 187],\n",
      "        [298,  37],\n",
      "        [461,  53],\n",
      "        [375, 475],\n",
      "        [300, 280],\n",
      "        [413, 256],\n",
      "        [388, 264],\n",
      "        [ 82, 273],\n",
      "        [ 70, 282],\n",
      "        [144, 275],\n",
      "        [182, 357],\n",
      "        [249, 362],\n",
      "        [244, 342],\n",
      "        [200, 321],\n",
      "        [243, 325],\n",
      "        [242, 302],\n",
      "        [191, 307],\n",
      "        [ 16, 382],\n",
      "        [ 96, 160],\n",
      "        [ 19, 383],\n",
      "        [425, 351],\n",
      "        [483, 352],\n",
      "        [342, 354],\n",
      "        [340, 378],\n",
      "        [325, 373],\n",
      "        [185, 289],\n",
      "        [170, 286],\n",
      "        [ 36, 265],\n",
      "        [ 63, 277],\n",
      "        [111, 311],\n",
      "        [344, 298],\n",
      "        [457, 319],\n",
      "        [443, 310],\n",
      "        [131, 481],\n",
      "        [101, 428],\n",
      "        [129,  63],\n",
      "        [240,  50],\n",
      "        [ 97, 106],\n",
      "        [141,  62],\n",
      "        [155,  27],\n",
      "        [171, 200],\n",
      "        [420, 487],\n",
      "        [303, 134],\n",
      "        [288, 242],\n",
      "        [355, 182],\n",
      "        [431,  88],\n",
      "        [ 88,  91],\n",
      "        [  1,  70],\n",
      "        [ 72, 327],\n",
      "        [160, 140],\n",
      "        [236, 484],\n",
      "        [176, 425],\n",
      "        [ 58, 404],\n",
      "        [407, 430],\n",
      "        [193, 388],\n",
      "        [377, 385],\n",
      "        [404, 123],\n",
      "        [378, 374],\n",
      "        [277, 232],\n",
      "        [133, 203],\n",
      "        [ 49, 224],\n",
      "        [ 87, 194],\n",
      "        [480, 125],\n",
      "        [387, 102],\n",
      "        [265, 112],\n",
      "        [ 14, 483],\n",
      "        [ 86, 292],\n",
      "        [282, 381],\n",
      "        [ 62, 295],\n",
      "        [115, 285],\n",
      "        [121, 367],\n",
      "        [326, 389],\n",
      "        [256, 427],\n",
      "        [112,  82],\n",
      "        [107,  86],\n",
      "        [120,  85],\n",
      "        [238,  77],\n",
      "        [187, 221],\n",
      "        [312, 141],\n",
      "        [453, 153],\n",
      "        [286, 171],\n",
      "        [479, 432],\n",
      "        [311, 464],\n",
      "        [456, 426],\n",
      "        [ 34, 453],\n",
      "        [421, 452],\n",
      "        [134, 407],\n",
      "        [140, 480],\n",
      "        [181,  46],\n",
      "        [411, 353],\n",
      "        [403, 246],\n",
      "        [ 85,  72],\n",
      "        [ 11,  34],\n",
      "        [ 91, 139],\n",
      "        [475, 212],\n",
      "        [275, 274],\n",
      "        [302, 332],\n",
      "        [329, 491],\n",
      "        [362, 360],\n",
      "        [360, 440],\n",
      "        [221, 442],\n",
      "        [254, 474],\n",
      "        [203, 470],\n",
      "        [274, 462],\n",
      "        [462, 387],\n",
      "        [380, 238],\n",
      "        [426, 168],\n",
      "        [446, 195],\n",
      "        [487, 230],\n",
      "        [142, 254],\n",
      "        [139, 240],\n",
      "        [ 33, 176],\n",
      "        [  3,   3],\n",
      "        [361, 446],\n",
      "        [263, 361],\n",
      "        [445, 380],\n",
      "        [113, 263],\n",
      "        [194, 363],\n",
      "        [481, 443],\n",
      "        [452, 429],\n",
      "        [470,   5],\n",
      "        [251, 355],\n",
      "        [168, 445],\n",
      "        [491, 479],\n",
      "        [  5, 251],\n",
      "        [257, 257]], device='cuda:0')))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "ipdb.pm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading RNN grids pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rnn_grid.pkl', 'rb') as f:\n",
    "    rnn_grids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_model = 0\n",
    "best_grid = None\n",
    "for model in rnn_grids:\n",
    "    if model[-1]['valid_acc'] > best_val_model:\n",
    "        best_grid = model\n",
    "        best_val_model = model[-1]['valid_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.646"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNEncoder(\n",
       "  (embedding): Embedding(21115, 300, padding_idx=0)\n",
       "  (encoder): GRU(300, 512, batch_first=True, bidirectional=True)\n",
       "  (classifier): ModuleList(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.0)\n",
       "    (3): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19027 words copied into nn.Embedding\n"
     ]
    }
   ],
   "source": [
    "best_conf = best_grid[-1]['configuration']\n",
    "rnnmodel = RNNEncoder(best_conf['rnn_hidden'], id2token, classifier_hidden=512, embedding_size=300, dropout=best_conf['dropout'])\n",
    "rnnmodel.load_state_dict(best_grid[-1]['model_dict'])\n",
    "rnnmodel = rnnmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc valid: 0.40224032586558045\n",
      "Acc valid: 0.40224032586558045\n",
      "Acc valid: 0.40224032586558045\n",
      "Acc valid: 0.40224032586558045\n",
      "Acc valid: 0.40224032586558045\n"
     ]
    }
   ],
   "source": [
    "for gengre in train_list_per_genre.keys():\n",
    "    _do_valid_rnn(rnnmodel, mnli_valid[genre]['rnn_loader'], metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "metrics = [[ii,i,j,k] for ii,(i,j,k) in enumerate(zip(best_grid[0]['train_loss'], best_grid[0]['train_acc'], best_grid[0]['valid_acc']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-d9612252d4c7334a052b313c65160758"
       },
       "datasets": {
        "data-d9612252d4c7334a052b313c65160758": [
         {
          "epoch": 0,
          "train_acc": 0.6646634615384616,
          "train_loss": 0.729027271270752,
          "valid_acc": 0.635
         },
         {
          "epoch": 1,
          "train_acc": 0.7073317307692307,
          "train_loss": 0.7260875105857849,
          "valid_acc": 0.656
         },
         {
          "epoch": 2,
          "train_acc": 0.7359525240384616,
          "train_loss": 0.6779547333717346,
          "valid_acc": 0.663
         },
         {
          "epoch": 3,
          "train_acc": 0.7674278846153846,
          "train_loss": 0.6927205324172974,
          "valid_acc": 0.661
         },
         {
          "epoch": 4,
          "train_acc": 0.7996544471153846,
          "train_loss": 0.5629647970199585,
          "valid_acc": 0.669
         },
         {
          "epoch": 5,
          "train_acc": 0.837890625,
          "train_loss": 0.6461130380630493,
          "valid_acc": 0.661
         },
         {
          "epoch": 6,
          "train_acc": 0.8560697115384616,
          "train_loss": 0.45474910736083984,
          "valid_acc": 0.645
         },
         {
          "epoch": 7,
          "train_acc": 0.8771784855769231,
          "train_loss": 0.4138783812522888,
          "valid_acc": 0.626
         },
         {
          "epoch": 8,
          "train_acc": 0.9033203125,
          "train_loss": 0.547460675239563,
          "valid_acc": 0.633
         },
         {
          "epoch": 9,
          "train_acc": 0.9036959134615384,
          "train_loss": 0.34896111488342285,
          "valid_acc": 0.599
         },
         {
          "epoch": 10,
          "train_acc": 0.9299879807692307,
          "train_loss": 0.3191346824169159,
          "valid_acc": 0.633
         },
         {
          "epoch": 11,
          "train_acc": 0.9411808894230769,
          "train_loss": 0.24994969367980957,
          "valid_acc": 0.622
         },
         {
          "epoch": 12,
          "train_acc": 0.9562049278846154,
          "train_loss": 0.24689428508281708,
          "valid_acc": 0.627
         },
         {
          "epoch": 13,
          "train_acc": 0.9523737980769231,
          "train_loss": 0.3516639471054077,
          "valid_acc": 0.603
         },
         {
          "epoch": 14,
          "train_acc": 0.9507211538461539,
          "train_loss": 0.2852811813354492,
          "valid_acc": 0.59
         },
         {
          "epoch": 15,
          "train_acc": 0.9610126201923077,
          "train_loss": 0.20948195457458496,
          "valid_acc": 0.624
         },
         {
          "epoch": 16,
          "train_acc": 0.9710036057692307,
          "train_loss": 0.1579096019268036,
          "valid_acc": 0.628
         },
         {
          "epoch": 17,
          "train_acc": 0.9709284855769231,
          "train_loss": 0.13218431174755096,
          "valid_acc": 0.628
         },
         {
          "epoch": 18,
          "train_acc": 0.9751352163461539,
          "train_loss": 0.15210440754890442,
          "valid_acc": 0.63
         },
         {
          "epoch": 19,
          "train_acc": 0.9758112980769231,
          "train_loss": 0.09668377786874771,
          "valid_acc": 0.612
         }
        ]
       },
       "encoding": {
        "x": {
         "field": "epoch",
         "scale": {},
         "type": "quantitative"
        },
        "y": {
         "field": "train_loss",
         "type": "quantitative"
        }
       },
       "height": 100,
       "mark": "line",
       "width": 200
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.DataFrame(metrics, columns=['epoch', 'train_loss', 'train_acc', 'valid_acc'])\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    alt.X('epoch', scale=alt.Scale()),\n",
    "    alt.Y('train_loss')).properties(\n",
    "        width=200,\n",
    "        height=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-d9612252d4c7334a052b313c65160758"
       },
       "datasets": {
        "data-d9612252d4c7334a052b313c65160758": [
         {
          "epoch": 0,
          "train_acc": 0.6646634615384616,
          "train_loss": 0.729027271270752,
          "valid_acc": 0.635
         },
         {
          "epoch": 1,
          "train_acc": 0.7073317307692307,
          "train_loss": 0.7260875105857849,
          "valid_acc": 0.656
         },
         {
          "epoch": 2,
          "train_acc": 0.7359525240384616,
          "train_loss": 0.6779547333717346,
          "valid_acc": 0.663
         },
         {
          "epoch": 3,
          "train_acc": 0.7674278846153846,
          "train_loss": 0.6927205324172974,
          "valid_acc": 0.661
         },
         {
          "epoch": 4,
          "train_acc": 0.7996544471153846,
          "train_loss": 0.5629647970199585,
          "valid_acc": 0.669
         },
         {
          "epoch": 5,
          "train_acc": 0.837890625,
          "train_loss": 0.6461130380630493,
          "valid_acc": 0.661
         },
         {
          "epoch": 6,
          "train_acc": 0.8560697115384616,
          "train_loss": 0.45474910736083984,
          "valid_acc": 0.645
         },
         {
          "epoch": 7,
          "train_acc": 0.8771784855769231,
          "train_loss": 0.4138783812522888,
          "valid_acc": 0.626
         },
         {
          "epoch": 8,
          "train_acc": 0.9033203125,
          "train_loss": 0.547460675239563,
          "valid_acc": 0.633
         },
         {
          "epoch": 9,
          "train_acc": 0.9036959134615384,
          "train_loss": 0.34896111488342285,
          "valid_acc": 0.599
         },
         {
          "epoch": 10,
          "train_acc": 0.9299879807692307,
          "train_loss": 0.3191346824169159,
          "valid_acc": 0.633
         },
         {
          "epoch": 11,
          "train_acc": 0.9411808894230769,
          "train_loss": 0.24994969367980957,
          "valid_acc": 0.622
         },
         {
          "epoch": 12,
          "train_acc": 0.9562049278846154,
          "train_loss": 0.24689428508281708,
          "valid_acc": 0.627
         },
         {
          "epoch": 13,
          "train_acc": 0.9523737980769231,
          "train_loss": 0.3516639471054077,
          "valid_acc": 0.603
         },
         {
          "epoch": 14,
          "train_acc": 0.9507211538461539,
          "train_loss": 0.2852811813354492,
          "valid_acc": 0.59
         },
         {
          "epoch": 15,
          "train_acc": 0.9610126201923077,
          "train_loss": 0.20948195457458496,
          "valid_acc": 0.624
         },
         {
          "epoch": 16,
          "train_acc": 0.9710036057692307,
          "train_loss": 0.1579096019268036,
          "valid_acc": 0.628
         },
         {
          "epoch": 17,
          "train_acc": 0.9709284855769231,
          "train_loss": 0.13218431174755096,
          "valid_acc": 0.628
         },
         {
          "epoch": 18,
          "train_acc": 0.9751352163461539,
          "train_loss": 0.15210440754890442,
          "valid_acc": 0.63
         },
         {
          "epoch": 19,
          "train_acc": 0.9758112980769231,
          "train_loss": 0.09668377786874771,
          "valid_acc": 0.612
         }
        ]
       },
       "encoding": {
        "x": {
         "field": "epoch",
         "scale": {},
         "type": "quantitative"
        },
        "y": {
         "field": "train_acc",
         "type": "quantitative"
        }
       },
       "height": 100,
       "mark": "line",
       "width": 200
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(df).mark_line().encode(\n",
    "    alt.X('epoch', scale=alt.Scale()),\n",
    "    alt.Y('train_acc')).properties(\n",
    "        width=200,\n",
    "        height=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-d9612252d4c7334a052b313c65160758"
       },
       "datasets": {
        "data-d9612252d4c7334a052b313c65160758": [
         {
          "epoch": 0,
          "train_acc": 0.6646634615384616,
          "train_loss": 0.729027271270752,
          "valid_acc": 0.635
         },
         {
          "epoch": 1,
          "train_acc": 0.7073317307692307,
          "train_loss": 0.7260875105857849,
          "valid_acc": 0.656
         },
         {
          "epoch": 2,
          "train_acc": 0.7359525240384616,
          "train_loss": 0.6779547333717346,
          "valid_acc": 0.663
         },
         {
          "epoch": 3,
          "train_acc": 0.7674278846153846,
          "train_loss": 0.6927205324172974,
          "valid_acc": 0.661
         },
         {
          "epoch": 4,
          "train_acc": 0.7996544471153846,
          "train_loss": 0.5629647970199585,
          "valid_acc": 0.669
         },
         {
          "epoch": 5,
          "train_acc": 0.837890625,
          "train_loss": 0.6461130380630493,
          "valid_acc": 0.661
         },
         {
          "epoch": 6,
          "train_acc": 0.8560697115384616,
          "train_loss": 0.45474910736083984,
          "valid_acc": 0.645
         },
         {
          "epoch": 7,
          "train_acc": 0.8771784855769231,
          "train_loss": 0.4138783812522888,
          "valid_acc": 0.626
         },
         {
          "epoch": 8,
          "train_acc": 0.9033203125,
          "train_loss": 0.547460675239563,
          "valid_acc": 0.633
         },
         {
          "epoch": 9,
          "train_acc": 0.9036959134615384,
          "train_loss": 0.34896111488342285,
          "valid_acc": 0.599
         },
         {
          "epoch": 10,
          "train_acc": 0.9299879807692307,
          "train_loss": 0.3191346824169159,
          "valid_acc": 0.633
         },
         {
          "epoch": 11,
          "train_acc": 0.9411808894230769,
          "train_loss": 0.24994969367980957,
          "valid_acc": 0.622
         },
         {
          "epoch": 12,
          "train_acc": 0.9562049278846154,
          "train_loss": 0.24689428508281708,
          "valid_acc": 0.627
         },
         {
          "epoch": 13,
          "train_acc": 0.9523737980769231,
          "train_loss": 0.3516639471054077,
          "valid_acc": 0.603
         },
         {
          "epoch": 14,
          "train_acc": 0.9507211538461539,
          "train_loss": 0.2852811813354492,
          "valid_acc": 0.59
         },
         {
          "epoch": 15,
          "train_acc": 0.9610126201923077,
          "train_loss": 0.20948195457458496,
          "valid_acc": 0.624
         },
         {
          "epoch": 16,
          "train_acc": 0.9710036057692307,
          "train_loss": 0.1579096019268036,
          "valid_acc": 0.628
         },
         {
          "epoch": 17,
          "train_acc": 0.9709284855769231,
          "train_loss": 0.13218431174755096,
          "valid_acc": 0.628
         },
         {
          "epoch": 18,
          "train_acc": 0.9751352163461539,
          "train_loss": 0.15210440754890442,
          "valid_acc": 0.63
         },
         {
          "epoch": 19,
          "train_acc": 0.9758112980769231,
          "train_loss": 0.09668377786874771,
          "valid_acc": 0.612
         }
        ]
       },
       "encoding": {
        "x": {
         "field": "epoch",
         "scale": {},
         "type": "quantitative"
        },
        "y": {
         "field": "valid_acc",
         "type": "quantitative"
        }
       },
       "height": 100,
       "mark": "line",
       "width": 200
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAACRCAYAAAAoyrYJAAAQdklEQVR4nO3df5RcZX3H8XfAEOIBhFoo9ESKyq8DpZhqKRCBRZRk5rkb8WhoCYI0nqA2icSE7HM3sWVR0Q01EcsP5ZeBSvZ5ZiQkISRWyGkoaAUtIJrEQkgKAQ4EK3oqPyq0mf7x3CWzszt7Z3fv7nzn5vs65znZ+bFP7mfvfb5z587c+4BSSimllFJKKaWUUkrl0dq1a1/evn17RZs2bf3bjh07djR7jI6J7u7uSrOXIQvbt2/XHIJojhajhUAWzSFLXnKkklQICl13HDSto3xcFLu2dutmmri00MSlhe3WzYxi1zato3xcoeuOgwb63bysMM0hS15ypBpOITh3iXtX1FE+pWj9R6PYfTaKXVcU+5uNdfdE1m+MrN8QWb/aWFcy1n3XWH+Lsf6GyPpritYvjaz7srH+G8a6kondA1HstxnrXoliX2mwvWqsf8rE7gFjXSmy/prb1/240m57ThyNv9FYysuGpzlazGCFwMQrD4lif6GJfTmK3eMm9i8NYbAOp70axX5bZN2DUew39WnWPWisfyp5Tt0+jPW/Dsvr50bWnzyWf8ss5GXD0xwtprYQmMX+T03srIn9D+sPOPeisf6xKPbrjfW3mNh/JewVDKX5RVHsLyzEPR9q7+w5/sO2/I5Gl/m8+asPLnSWT4g63DnFTneRiZ394o0/qBjrnu23rNb9yli/Kor93GmLe/4s+79gtvKy4WmOFtPd3V0pxj3TIuuuM7H/z/6vsO7hyJa+WOjwp567xL2r2ctbT+8KK3SsmlS0pfMj668x1j1srHujdo8hsn51ZP1lYY+hMq7Zy14tLxue5mghU+Py0d3d3bUD/5XI+tWms/SpQmf50GYvY6MGW2HttvzByJY6jPVrIuv/u99bCevXmA4/38Tl9w/2f7R3rXv71Lh8tOl0ZxRt6fxip/u8sf6vs8pgYj9j5YaHK4UOf2pbV/mArPpthrwMoLzkSBUKgdtprL+hYH1hRld5v2Yv03AMZYUZ60431v/9QG9/TOxeNtavCQczvYtid7+J/RO1BaSmbSvG7pLhLruxpU8a67f2f1vjn4livz6K/dWR9RebuPz+tq4V+w/UR6GzfGh7Z8/xhc7SFNPppkcd/m+MdZebDvfpsS4q02J31Lr7H60Ubel8E7tZkfWXmdgvMbHrjqy7LrL+dmP9KmPdvf2OBdVr1j0Y9vD8Y8b6reF4kdsZWbcrsv43vceOTOxfMtY7Y/3nirZ80kiz7FWFoNnLkIXhrrC2rvIBptNNT94abUk5mPm7yLonk086ko3UvVg9cE3sZjX6f5vYzUoOgL517GX+N9dXTOweGuygaPI7PzGx226s/20jB2JN7Naa2M+oV0iyMDUuH22s+25k/f+O8kHlxpt1uyLrvhfFfu5wCoPkQnAhsAroBjqBg2sefxvwj8C3kucsHKyzvb0Q1Cp0rJpkYn9pZP2CYly6oL2zfFax0x87vWPtgQM9v61rxf7G+nlR7HZWDeidkXVzCvM2TOjX/7wNE0zs/zZ5tX/r+cb6eW1dK/avzmHile8xnW66sW6xiV1PcoC27gZvrN/at0j5TVHsf1L71s9Y70ynm57F3wug0Fk+IRlsb/0/c5evqxjrV5nY3WZif21k/deMdYuN9fOKsbukGJc+bmxpahS7tiyb6SidbeLSQmP9GhO7lwfc44vd2uKi8uGNZJNcCJ4Hxic/dwPzax6/ALit6vYpg3WmhSA7kXWzI+t3VL/CR9YvOO0L5YmnfaE8MbJ+QZ89iPBR6ezqPhrJEVl/ctRRPqWwyL/3vPmra18I+jn38rsOi6ybE1m/sd8eTuxvLsY904aTt2jLJxnrSjV7K6sKsZssYX0AFGI32XT4+dWFwcTu9Ub3jKTkqHUo8HjV7dnADTXPWQJ44EngR8CHButQC0H2wrcia95mWP/anlclv6XdupkD/e5o5zDxykMi6y821t1Ts3w/i6zfaKz/dmTdnKItnVnvI91C7CZH1t9dVfD+z1hXKnSWTxirHMNViN3kKHZ/1ejzpeZ4D/DTqtszCG8Dqn0LeIRQNM5OfgZg6dKlV3R3d1dqW7PP8Mpru3vTo5U5y9a9NdjmLFtXuXvTo01frt629YltlfK9P60sufEHlZlX3jngW46ZV95ZWXjthsqylZsqt6/7cWXRdd/v8/gVt9xXeeixrU3PMppttAf1cIwDtlXd/izwuZrnfI2wV9DrF8Bh9TrUPYLRV4x7pkUd7pxGntvMHIXO8qHGlqYWrY+Tb2duM9bvHqBA/D6y7qZ2Wz6yXl+S18dQSM7xQ+A4YF9gPfDB5P53Ew4UfgJYndx3EPDzwTrTQiCLtBzTO9YeWLSlM8NHgO42E/vrpy5edUTa70nLMVySc0wFthNe6b9Tdf/zwJ8QCsS3CccH/o1QGOrSQiCL5pBFeo6JQNrHHwcD+6R1pIVAFs0hS15ypNJCIIvmkCUvOVJpIZBFc8iSlxyptBDIojlkyUuOVFoIZNEcsuQlRyotBLJoDlnykiOVFgJZNIcsecmRSguBLJpDlqxyTATmAicRvub7VQb5um8zaCGQRXPIklWO7wBvAh8AjgBep+9JQ02nhUAWzSFLVjmeAxZV3T4dqABHZdF5FrQQyKI5ZMkqx9PAQ8A7CW8TriEUgoaujjIWtBDIojlkySrHHGA3YfD3trVZdJwVLQSyaA5ZssxxOHAp8GXgLwnXFBBDC4EsmkMW/dSgxeiGJ4vm6Es/NRgjuuHJojn60k8NxohueLJojr6eRj81GBO64cmiOfrSTw3GiG54smiO/vRTgzGgG54smqM/Q5iarLfdklXHDUgtOloIZNEcsmSV40b6vi2oAK+NsM+0uQ97HQI8BQw61bcWAlk0hyxZ5dgJzAPuAz4NXAasGWGfaXMfQtgT+AfgXuDPB+tMC4EsmkOWrHK8RBioi4EVhE8O3mT4XypqZO5DgA5gCuHApBaCFqI5ZMkqx02EtwNtyb+/A34D7DfM/hqZ+7ANWJb8rIWgxWgOWbLKsR/wUcKu/KcIxwymjKC/RuY+3EiY5eg+4FfAw8CJoJOgatM2nDaC8ZrqGODjw/zdtLkPD09+fjfwz0A7MKFeZ7pHIIvmkGW0c5xA2EMYjrS5D6utQt8atBTNIYvkQgCNzX3YEC0EsmgOWaQXgsxoIZBFc8iihaDF6IYni+ZojBaCjOmGJ4vmCCYCb09pfzTCZcyEFgJZNIcsI83xAv3PMahuYmghkEVzyDLSHB3Al4C7gDeAdcA3gWeBe0a8dBnSQiCL5pAlqxy/AGzV7Y8Qzj6cmEXnWdBCIIvmkCWrHLsIX/XtvVTZVYS3BpOy6DwLWghk0RyyZJWjizDwdxPeIlQIXwsWQwuBLJpDlixzHA8sJJwReAawT1YdZ0ELgSyaQ5aR5phKOOnnLKAwQBNDC4EsmkOWkeZ4HVgAPIl+fDgmdMOTRXMEZwNHAqcB5wzQxNBCIIvmkCWLQjB1kCaGFgJZNIcsI83xEvrNwjGlG54smiOYQrh2YL0mhhYCWTSHLFnmaOYEJ6m0EMiiOWTJKsdoTHCSKS0EsmgOWbLKMRoTnGRKC4EsmkOWrHJkPcFJ5rQQyKI5ZMkqR9YTnGROC4EsmkOWrHJkPcEJpE+Celjy+K2E+Q8XDNaZFgJZNIcsWeVYApxOA9OTD0HaJKizCBdGIfl/dwEH1OtMC4EsmkOWrHL8B+EtwXbgSuDYEfbX6CSovc4mTHlWlxYCWTSHLFnlOBD4GOFYwXOEojDowEzRyCSoEPYE5gO/BCb33qlzH2rTNvQ2gvHaxwTCJcqWA79lZF8xbmQSVAh7CSvof/ygH90jkEVzyJJVjhXAq4TB/zzwdeB9I+wzbRLUGYBrtDMtBLJoDlmyyvHvhGJwDtldmShtEtTrCNOhP1PVjqjXmRYCWTSHLFnleFsWnQxAJ0GtoRueLJqjxWghkEVzyJKXHKm0EMiiOWTJS45UWghk0Ryy5CVHKi0EsmgOWfKSI5UWAlk0hyx5yZFKC4EsmkOWvORIpYVAFs0hS15ypNJCIIvmkCUvOVJpIZBFc8iSlxyptBDIojlkyUuOVFoIZNEcsuQlRyotBLJoDlnykiOVFgJZNIcsecmRSguBLJpDlrzkSKWFQBbNIUtecqTSQiCL5pAlLzlSaSGQRXPIkpccqbQQyKI5ZMlLjlRaCGTRHLLkJUcqLQSyaA5Z8pIjlRYCWTSHLJJzpE2CegjQQ5jk5KuEy5/XpYVAFs0hi+QcaZOgLgDi5OeJwH8xyJwKWghk0RyySM3RyCSo1xPmW+z1PGGq9AFpIZBFc8giNUcjk6D+E2Cqbm8B/gAGngR1+fLluweaGFWbNm3dlVtvvfXNUR3Rw9TIJKiLgM9U3f75YB12d+djj0BzyKI5Rl/aJKjnEg4WApwKbBysM8lBh0JzyKI5Rl/aJKjjge8D/wq8AJw8WGeSgw6F5pBFc4yNRiZBnUQDk7BKD9oozSGL5mgxS5cuvaLZy5AFzSGL5lBKKaWUUkqplpV2/oJkJwNrgauSdnZzF2dIxgEfIHwb9Kqq+1ttfdTL8RngJvasm6PGfMnqmw3cDSwDbiQs25DO08mjtPMXJJsJXELYGFvNeGAJsAa4uur+Vlsf9XLcRBhgEtfNFvacg/N5wt95SOfp5E0j5y9I9iVgK2Hw3AH8cXMXZ1hms2cAtfL6qM4B4bssjwJPEwbavk1YpjTjCV+6KzDE83TyppHzFyS7CDiDsJFdRdjgWk31AGrl9VFbCLoIhfkAwmCb1oRlGswxwI+AbxBe+euep7M3aOT8hVZxDPBIsxdiGKoHUCuvj9pCUPvYsjFcljQnEL6dW12chnSeTh7VO3+hFdzFngOEFyFrY2tU7QBq1fVRnWMiYaC9M7l9K9DejIWq42fAiTX3Dek8nTyqd/5CKziLsFLXE44CH9vcxRmW2kLQquujNscC4CHgX4Cbgf2bsVAD+EPgDeCZqnY1QzxPJ68aOX9Bqn0IKzdPWnl9VJtIOEbQSho6T0cppZRSSimllFJKKaWUUkoppZQS5MPA74Ezm70gSqnmOReoAG1NXg6lVB3thBNWXgQ88I7k/juBawnfZ98CXA5MSB77C+Bh4BXCadUzkvv3I5w/8XTyeO+1CXoLwdcJX0feBpw3SnmUUkM0Hvg14byHS5Of70we20wYvKsJVyCqAOcnjz1BKACXAvcTdvsPAT6RPK8HuA3YTThzrrcQPA7MAZ4Fdo1iLqXUEEwjDNDrgb8jDNQ3COdDbAYeqHruC0AJeF/yOxcm95+U3J4FrEx+D8LewUcIV/3pLQQXJI9dRygSSikB5hMG6A2Eqyf1tvGEAX1/1XO3sec06gp7TtM9Krm9AHiQcAYfhGsVTAIOpP8xguXJbYmXBVNqrzOFMCCXE642dCNwTfLYZsKrdoFwwZHeV/19CccT7gUmE671txs4knANvf8BLq76naloIVBKvMuBnYSBuYs9H/FtJhxEfC557BH2XArrk8Bryf272XM14EnAL5P7K8AKwtsMLQRKtYBxhD2C6gt2biYcKBzHwBdZnQAcT9j1r7YP8F7yd80FpfZKvYVAKbUXayN8X0AppZRSSimllFJKKaVUHvw/3kI/asx5c0cAAAAASUVORK5CYII=",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(df).mark_line().encode(\n",
    "    alt.X('epoch', scale=alt.Scale()),\n",
    "    alt.Y('valid_acc')).properties(\n",
    "        width=200,\n",
    "        height=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
